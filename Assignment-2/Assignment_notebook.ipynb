{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FoDS Assignment-3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTuvu2XPlDq_"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.preprocessing import PolynomialFeatures\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJJjvdQ0Or3-"
      },
      "source": [
        "class color:\n",
        "   PURPLE = '\\033[95m'\n",
        "   CYAN = '\\033[96m'\n",
        "   DARKCYAN = '\\033[36m'\n",
        "   BLUE = '\\033[94m'\n",
        "   GREEN = '\\033[92m'\n",
        "   YELLOW = '\\033[93m'\n",
        "   RED = '\\033[91m'\n",
        "   BOLD = '\\033[1m'\n",
        "   UNDERLINE = '\\033[4m'\n",
        "   END = '\\033[0m'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4iH8xAm7R_N",
        "outputId": "8f036747-ba1f-4637-cecc-629c192a6d1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cV581BFd8GUt",
        "outputId": "ffb25ce8-e90e-4433-ff43-ea9f9fe5ac51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/insurance.txt')\n",
        "data = data.drop(['children'], axis = 1)\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>30.970</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>31.920</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>36.850</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>25.800</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>29.070</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     bmi      charges\n",
              "0      19  27.900  16884.92400\n",
              "1      18  33.770   1725.55230\n",
              "2      28  33.000   4449.46200\n",
              "3      33  22.705  21984.47061\n",
              "4      32  28.880   3866.85520\n",
              "...   ...     ...          ...\n",
              "1333   50  30.970  10600.54830\n",
              "1334   18  31.920   2205.98080\n",
              "1335   18  36.850   1629.83350\n",
              "1336   21  25.800   2007.94500\n",
              "1337   61  29.070  29141.36030\n",
              "\n",
              "[1338 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpjUOw6e8XXV"
      },
      "source": [
        "X = data[['age','bmi']]\n",
        "Y = data['charges']\n",
        "Y = Y.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyafX7kl9CEu"
      },
      "source": [
        "def poly_features(X, deg):\n",
        "  poly = PolynomialFeatures(degree = deg)\n",
        "  ftr = poly.fit_transform(X)\n",
        "  return ftr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86PdNHqV23f8"
      },
      "source": [
        "def splitData(X, Y):\n",
        "    np.random.seed(0)\n",
        "    msk = np.random.rand(len(X)) < 0.7\n",
        "    \n",
        "    featureTrain = X[msk,:]\n",
        "    targetTrain = Y[msk]\n",
        "    featureTest = X[~msk,:]\n",
        "    targetTest = Y[~msk]\n",
        "    \n",
        "    return featureTrain, featureTest, targetTrain, targetTest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv3Xi4mWyyGs"
      },
      "source": [
        "def splitDataReg(X, Y):\n",
        "    np.random.seed(0)\n",
        "    msk = np.random.rand(len(X)) < 0.7\n",
        "    \n",
        "    featureTrain = X[msk,:]\n",
        "    targetTrain = Y[msk]\n",
        "    \n",
        "    \n",
        "    featureTest_And_val = X[~msk,:]\n",
        "    targetTest_And_val = Y[~msk]\n",
        "\n",
        "    msk2 = np.random.rand(len(featureTest_And_val)) < 0.67\n",
        "\n",
        "    featureTest = featureTest_And_val[~msk2,:]\n",
        "    targetTest = targetTest_And_val[~msk2]\n",
        "\n",
        "    featureValidation = featureTest_And_val[msk2,:]\n",
        "    targetValidation = targetTest_And_val[msk2]\n",
        "    \n",
        "    #print(len(featureTrain), len(featureTest))\n",
        "    return featureTrain, featureTest, targetTrain, targetTest, featureValidation, targetValidation\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYXh4S-R19oN"
      },
      "source": [
        "def standardize(feature_matrix, target):\n",
        "  min_array=np.amin(feature_matrix,axis=0)\n",
        "  max_array=np.amax(feature_matrix,axis=0)\n",
        "  for i in range(1,feature_matrix.shape[1]):  # standardize features\n",
        "    for j in range(feature_matrix.shape[0]):\n",
        "      feature_matrix[j][i]=((feature_matrix[j][i]-min_array[i])/(max_array[i]-min_array[i]))\n",
        "  targetMin=target.min();\n",
        "  targetMax=target.max();\n",
        "  target=(target-target.min())/(target.max()-target.min()) # standardize target\n",
        "  return (feature_matrix,target,targetMax,targetMin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCb-d5aI0GEL"
      },
      "source": [
        "**Without regularization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-8bx_bKBT0a"
      },
      "source": [
        "def cost_function(theta, X, Y):\n",
        "  m = X.shape[0]\n",
        "  pred = X.dot(theta)\n",
        "  cost = (1/(2*m))*np.sum(np.square(Y-pred))\n",
        "  return cost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtakD44oApAx"
      },
      "source": [
        "def gradient_descent(X, Y, theta, alpha, num_iters, Y_max, Y_min):\n",
        "  m = X.shape[0]\n",
        "  for i in range(num_iters):\n",
        "    pred = X.dot(theta)\n",
        "    cost_der = (1/m)*np.dot(X.transpose(), (pred-Y))\n",
        "    theta = theta - alpha*cost_der    # update weights\n",
        "\n",
        "    if i%50 == 0:                    # print error after every 50 iterations\n",
        "      Y_pred = X.dot(theta)\n",
        "      rmse = math.sqrt(np.mean(np.square(Y_pred - Y)))\n",
        "      rmse = rmse*(Y_max - Y_min) + Y_min\n",
        "      print(\"Iteration \" + str(i) + \" : \" + str(rmse))\n",
        "\n",
        "  return theta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFziRo09C8Ca"
      },
      "source": [
        "def gradient_descent_model(X_train, Y_train, X_test, Y_test, Y_train_max, Y_train_min, Y_test_max, Y_test_min, alpha, num_iters):          \n",
        "  theta = np.zeros(X_train.shape[1])\n",
        "  theta = np.transpose(theta)\n",
        "  theta = gradient_descent(X_train, Y_train, theta, alpha, num_iters, Y_train_max, Y_train_min)  # calculate weights using gradient descent\n",
        "\n",
        "  Y_pred_train = X_train.dot(theta)\n",
        "  Y_pred_test = X_test.dot(theta)\n",
        "\n",
        "  rmse_train = math.sqrt(np.mean(np.square(Y_pred_train - Y_train)))   #calcuate and print train and test errors\n",
        "  rmse_train = rmse_train*(Y_train_max - Y_train_min) + Y_train_min\n",
        "  rmse_test = math.sqrt(np.mean(np.square(Y_pred_test - Y_test)))\n",
        "  rmse_test = rmse_test*(Y_test_max - Y_test_min) + Y_test_min\n",
        "\n",
        "  print(\"Final training set RMSE : \" + str(rmse_train))\n",
        "  print(\"Final test set RMSE : \" + str(rmse_test))\n",
        "  print(theta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUPxUKeky22z",
        "outputId": "bf526338-1a0a-447d-b4fb-db0349b51ad4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(10):                                      #apply polynomial regression for polynomials of degrees from 1 to 10\n",
        "  Xi = poly_features(X, i+1)\n",
        "  X_train, X_test, Y_train, Y_test = splitData(Xi, Y)       #split data into train and test sets           \n",
        "  X_train, Y_train, Y_train_max, Y_train_min = standardize(X_train, Y_train) #standardize train set\n",
        "  X_test, Y_test, Y_test_max, Y_test_min = standardize(X_test, Y_test) #stanardize test set\n",
        "  print(\"\\nPOLYNOMIAL OF DEGREE \" + str(i+1))\n",
        "  gradient_descent_model(X_train, Y_train, X_test, Y_test, Y_train_max, Y_train_min, Y_test_max, Y_test_min, 0.01, 1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "POLYNOMIAL OF DEGREE 1\n",
            "Iteration 0 : 17905.623351554874\n",
            "Iteration 50 : 14100.66081103754\n",
            "Iteration 100 : 12979.593752988978\n",
            "Iteration 150 : 12678.807268619246\n",
            "Iteration 200 : 12593.544319943116\n",
            "Iteration 250 : 12562.513227255473\n",
            "Iteration 300 : 12545.417008316386\n",
            "Iteration 350 : 12532.332705048895\n",
            "Iteration 400 : 12520.796564662853\n",
            "Iteration 450 : 12510.168571534463\n",
            "Iteration 500 : 12500.256019001654\n",
            "Iteration 550 : 12490.977780630858\n",
            "Iteration 600 : 12482.282329214753\n",
            "Iteration 650 : 12474.127597385897\n",
            "Iteration 700 : 12466.475914937415\n",
            "Iteration 750 : 12459.292629082403\n",
            "Iteration 800 : 12452.545631546063\n",
            "Iteration 850 : 12446.205115713836\n",
            "Iteration 900 : 12440.243398447394\n",
            "Iteration 950 : 12434.634765761857\n",
            "Final training set RMSE : 12429.457840641535\n",
            "Final test set RMSE : 13009.745375207587\n",
            "[0.10045177 0.12978462 0.08188405]\n",
            "\n",
            "POLYNOMIAL OF DEGREE 2\n",
            "Iteration 0 : 17860.817057744775\n",
            "Iteration 50 : 13410.68216020709\n",
            "Iteration 100 : 12552.891593267324\n",
            "Iteration 150 : 12406.55242718879\n",
            "Iteration 200 : 12377.822324139068\n",
            "Iteration 250 : 12368.29003515617\n",
            "Iteration 300 : 12362.33765845373\n",
            "Iteration 350 : 12357.446093711964\n",
            "Iteration 400 : 12353.157530315902\n",
            "Iteration 450 : 12349.345062350525\n",
            "Iteration 500 : 12345.940930219442\n",
            "Iteration 550 : 12342.893026412814\n",
            "Iteration 600 : 12340.157222509306\n",
            "Iteration 650 : 12337.695414764452\n",
            "Iteration 700 : 12335.474566857794\n",
            "Iteration 750 : 12333.465997840367\n",
            "Iteration 800 : 12331.644785604149\n",
            "Iteration 850 : 12329.989255071296\n",
            "Iteration 900 : 12328.480537166393\n",
            "Iteration 950 : 12327.102188500916\n",
            "Final training set RMSE : 12325.864056635874\n",
            "Final test set RMSE : 12963.346663554885\n",
            "[0.07563485 0.07032944 0.05507751 0.06625632 0.06311297 0.04456454]\n",
            "\n",
            "POLYNOMIAL OF DEGREE 3\n",
            "Iteration 0 : 17821.08344443793\n",
            "Iteration 50 : 13008.604051390841\n",
            "Iteration 100 : 12390.925337238265\n",
            "Iteration 150 : 12323.77023862383\n",
            "Iteration 200 : 12315.800588028558\n",
            "Iteration 250 : 12314.11036148196\n",
            "Iteration 300 : 12313.170258257289\n",
            "Iteration 350 : 12312.391914206952\n",
            "Iteration 400 : 12311.702390288636\n",
            "Iteration 450 : 12311.084241170192\n",
            "Iteration 500 : 12310.527414522328\n",
            "Iteration 550 : 12310.023959903958\n",
            "Iteration 600 : 12309.567237465939\n",
            "Iteration 650 : 12309.151639862825\n",
            "Iteration 700 : 12308.772404673742\n",
            "Iteration 750 : 12308.425466222869\n",
            "Iteration 800 : 12308.107335670025\n",
            "Iteration 850 : 12307.815003532634\n",
            "Iteration 900 : 12307.545860266811\n",
            "Iteration 950 : 12307.297631424772\n",
            "Final training set RMSE : 12307.072736991606\n",
            "Final test set RMSE : 12985.509385093808\n",
            "[0.0733288  0.04599963 0.04408705 0.04128003 0.04205472 0.03428315\n",
            " 0.03698621 0.03643697 0.03419164 0.02556621]\n",
            "\n",
            "POLYNOMIAL OF DEGREE 4\n",
            "Iteration 0 : 17788.589033251425\n",
            "Iteration 50 : 12798.873454892728\n",
            "Iteration 100 : 12347.0335674691\n",
            "Iteration 150 : 12312.376483610553\n",
            "Iteration 200 : 12309.094184904165\n",
            "Iteration 250 : 12308.274868347533\n",
            "Iteration 300 : 12307.763699972907\n",
            "Iteration 350 : 12307.372452270343\n",
            "Iteration 400 : 12307.064037137667\n",
            "Iteration 450 : 12306.818120543243\n",
            "Iteration 500 : 12306.619900427972\n",
            "Iteration 550 : 12306.458223365666\n",
            "Iteration 600 : 12306.324646627269\n",
            "Iteration 650 : 12306.212767650726\n",
            "Iteration 700 : 12306.117722183984\n",
            "Iteration 750 : 12306.03580686784\n",
            "Iteration 800 : 12305.964195198427\n",
            "Iteration 850 : 12305.90072368361\n",
            "Iteration 900 : 12305.843730778739\n",
            "Iteration 950 : 12305.791935514078\n",
            "Final training set RMSE : 12305.745261851276\n",
            "Final test set RMSE : 13009.877859362405\n",
            "[0.07669894 0.03669923 0.03971513 0.03069039 0.03293665 0.02969326\n",
            " 0.0256953  0.02581769 0.02568252 0.02113886 0.02180607 0.02064664\n",
            " 0.02001539 0.01868247 0.01449585]\n",
            "\n",
            "POLYNOMIAL OF DEGREE 5\n",
            "Iteration 0 : 17761.953449104552\n",
            "Iteration 50 : 12696.096839831342\n",
            "Iteration 100 : 12351.020144584467\n",
            "Iteration 150 : 12326.055321538322\n",
            "Iteration 200 : 12320.356724422172\n",
            "Iteration 250 : 12316.951085127932\n",
            "Iteration 300 : 12314.556818004454\n",
            "Iteration 350 : 12312.844621448136\n",
            "Iteration 400 : 12311.612885161547\n",
            "Iteration 450 : 12310.720905979004\n",
            "Iteration 500 : 12310.069411442704\n",
            "Iteration 550 : 12309.588291296945\n",
            "Iteration 600 : 12309.228015309545\n",
            "Iteration 650 : 12308.953579786194\n",
            "Iteration 700 : 12308.740235610678\n",
            "Iteration 750 : 12308.570473618869\n",
            "Iteration 800 : 12308.431897286526\n",
            "Iteration 850 : 12308.315721517925\n",
            "Iteration 900 : 12308.215713181944\n",
            "Iteration 950 : 12308.127443312735\n",
            "Final training set RMSE : 12308.04928449048\n",
            "Final test set RMSE : 13025.900462908057\n",
            "[0.08038931 0.03365471 0.03806979 0.02648878 0.02916846 0.02765984\n",
            " 0.02068994 0.02098694 0.02172215 0.0189854  0.01632125 0.01531216\n",
            " 0.01515023 0.01490653 0.01241218 0.01313305 0.01153305 0.01094203\n",
            " 0.01062361 0.00993784 0.00773955]\n",
            "\n",
            "POLYNOMIAL OF DEGREE 6\n",
            "Iteration 0 : 17740.332502644775\n",
            "Iteration 50 : 12653.944935395455\n",
            "Iteration 100 : 12373.085967442717\n",
            "Iteration 150 : 12346.162932613948\n",
            "Iteration 200 : 12334.794929678039\n",
            "Iteration 250 : 12327.383697925261\n",
            "Iteration 300 : 12322.352633447272\n",
            "Iteration 350 : 12318.904116942309\n",
            "Iteration 400 : 12316.516643004365\n",
            "Iteration 450 : 12314.842678854471\n",
            "Iteration 500 : 12313.650158854687\n",
            "Iteration 550 : 12312.783909278438\n",
            "Iteration 600 : 12312.139986718565\n",
            "Iteration 650 : 12311.64860208667\n",
            "Iteration 700 : 12311.262757542898\n",
            "Iteration 750 : 12310.950683391118\n",
            "Iteration 800 : 12310.69080196873\n",
            "Iteration 850 : 12310.468371961748\n",
            "Iteration 900 : 12310.273250353233\n",
            "Iteration 950 : 12310.098397930577\n",
            "Final training set RMSE : 12309.941944316204\n",
            "Final test set RMSE : 13032.481026879872\n",
            "[0.08289745 0.03313991 0.03759731 0.02516024 0.02791048 0.02687779\n",
            " 0.01873221 0.01907015 0.02011789 0.01804851 0.01392796 0.01296669\n",
            " 0.01300233 0.01322254 0.01144056 0.01046157 0.00891999 0.00842015\n",
            " 0.00841626 0.00828907 0.0068076  0.00798149 0.00614349 0.00524294\n",
            " 0.00479257 0.00486618 0.00487021 0.00369691]\n",
            "\n",
            "POLYNOMIAL OF DEGREE 7\n",
            "Iteration 0 : 17722.54383886498\n",
            "Iteration 50 : 12644.493716857858\n",
            "Iteration 100 : 12399.6471335519\n",
            "Iteration 150 : 12364.964719716043\n",
            "Iteration 200 : 12346.77010413763\n",
            "Iteration 250 : 12335.175660421326\n",
            "Iteration 300 : 12327.641293288643\n",
            "Iteration 350 : 12322.68392427124\n",
            "Iteration 400 : 12319.370840158183\n",
            "Iteration 450 : 12317.112427684\n",
            "Iteration 500 : 12315.535128241863\n",
            "Iteration 550 : 12314.401561848845\n",
            "Iteration 600 : 12313.560273484283\n",
            "Iteration 650 : 12312.914116927985\n",
            "Iteration 700 : 12312.400355441514\n",
            "Iteration 750 : 12311.97812562968\n",
            "Iteration 800 : 12311.620528735126\n",
            "Iteration 850 : 12311.309631290073\n",
            "Iteration 900 : 12311.033296365196\n",
            "Iteration 950 : 12310.783167997824\n",
            "Final training set RMSE : 12310.557808869966\n",
            "Final test set RMSE : 13032.139190097356\n",
            "[0.08417834 0.03345254 0.03755784 0.02498831 0.02771292 0.02665522\n",
            " 0.01815477 0.01851834 0.01964388 0.01771543 0.01304403 0.01212366\n",
            " 0.01224511 0.01262315 0.01105843 0.00936001 0.00786636 0.00742364\n",
            " 0.00755716 0.00764432 0.00641829 0.00673122 0.00494774 0.00408287\n",
            " 0.00376594 0.00401083 0.00422615 0.00332459 0.00484678 0.00289978\n",
            " 0.00172671 0.00123056 0.00134722 0.00169536 0.00194623 0.00132809]\n",
            "\n",
            "POLYNOMIAL OF DEGREE 8\n",
            "Iteration 0 : 17707.56979014812\n",
            "Iteration 50 : 12652.386056901842\n",
            "Iteration 100 : 12424.992233432044\n",
            "Iteration 150 : 12379.814804649288\n",
            "Iteration 200 : 12354.777944093245\n",
            "Iteration 250 : 12339.470079857441\n",
            "Iteration 300 : 12329.95855137382\n",
            "Iteration 350 : 12323.949372310286\n",
            "Iteration 400 : 12320.069765112234\n",
            "Iteration 450 : 12317.495596544197\n",
            "Iteration 500 : 12315.730331457278\n",
            "Iteration 550 : 12314.473274804039\n",
            "Iteration 600 : 12313.541057810346\n",
            "Iteration 650 : 12312.820832948853\n",
            "Iteration 700 : 12312.24233729257\n",
            "Iteration 750 : 12311.761183267261\n",
            "Iteration 800 : 12311.348834373432\n",
            "Iteration 850 : 12310.986566256453\n",
            "Iteration 900 : 12310.66180830703\n",
            "Iteration 950 : 12310.365911103538\n",
            "Final training set RMSE : 12310.098041588537\n",
            "Final test set RMSE : 13027.682732900297\n",
            "[ 8.45620258e-02  3.38873699e-02  3.76392376e-02  2.51885350e-02\n",
            "  2.78960441e-02  2.66608535e-02  1.81400696e-02  1.85527730e-02\n",
            "  1.96729611e-02  1.76659591e-02  1.28527391e-02  1.19958797e-02\n",
            "  1.21638921e-02  1.25585363e-02  1.09748107e-02  9.03250110e-03\n",
            "  7.60563674e-03  7.21644050e-03  7.40162799e-03  7.52586160e-03\n",
            "  6.31713703e-03  6.30208343e-03  4.58628167e-03  3.77050279e-03\n",
            "  3.51708696e-03  3.81885867e-03  4.07879993e-03  3.21725457e-03\n",
            "  4.34316779e-03  2.46459381e-03  1.33977300e-03  8.98352789e-04\n",
            "  1.07560962e-03  1.49131653e-03  1.78562952e-03  1.22153695e-03\n",
            "  2.92278329e-03  9.42207747e-04 -3.62213719e-04 -1.03005794e-03\n",
            " -9.70786191e-04 -4.88459617e-04  9.85193340e-05  3.08109607e-04\n",
            " -2.52189189e-05]\n",
            "\n",
            "POLYNOMIAL OF DEGREE 9\n",
            "Iteration 0 : 17694.935461416\n",
            "Iteration 50 : 12668.868292555024\n",
            "Iteration 100 : 12446.41451766665\n",
            "Iteration 150 : 12389.952130693058\n",
            "Iteration 200 : 12358.817105202907\n",
            "Iteration 250 : 12340.629567198917\n",
            "Iteration 300 : 12329.823891545775\n",
            "Iteration 350 : 12323.26681786295\n",
            "Iteration 400 : 12319.175103785185\n",
            "Iteration 450 : 12316.53022674942\n",
            "Iteration 500 : 12314.747346116357\n",
            "Iteration 550 : 12313.488062986311\n",
            "Iteration 600 : 12312.554523167679\n",
            "Iteration 650 : 12311.829455040564\n",
            "Iteration 700 : 12311.242135778595\n",
            "Iteration 750 : 12310.749002153836\n",
            "Iteration 800 : 12310.32254566035\n",
            "Iteration 850 : 12309.944905976196\n",
            "Iteration 900 : 12309.604138963257\n",
            "Iteration 950 : 12309.292015076544\n",
            "Final training set RMSE : 12309.008291995753\n",
            "Final test set RMSE : 13021.45148437517\n",
            "[ 8.43938944e-02  3.41813052e-02  3.77183527e-02  2.54170930e-02\n",
            "  2.81515487e-02  2.67385420e-02  1.82936785e-02  1.87878122e-02\n",
            "  1.98884497e-02  1.77335095e-02  1.29345122e-02  1.21694807e-02\n",
            "  1.23770357e-02  1.27312949e-02  1.10284843e-02  9.05180917e-03\n",
            "  7.71715252e-03  7.38857236e-03  7.58703820e-03  7.66251556e-03\n",
            "  6.35681724e-03  6.26979761e-03  4.64363404e-03  3.89254219e-03\n",
            "  3.67005339e-03  3.96897129e-03  4.18543702e-03  3.24466416e-03\n",
            "  4.26936223e-03  2.47726203e-03  1.41469520e-03  1.01415536e-03\n",
            "  1.20830679e-03  1.60935857e-03  1.86788314e-03  1.23897812e-03\n",
            "  2.81598521e-03  9.18868221e-04 -3.26141583e-04 -9.49381486e-04\n",
            " -8.67781340e-04 -3.75538518e-04  1.90905954e-04  3.70877413e-04\n",
            " -1.55201287e-05  1.74637101e-03 -2.24607890e-04 -1.58649390e-03\n",
            " -2.40187277e-03 -2.45896210e-03 -2.00184519e-03 -1.23881043e-03\n",
            " -6.02146027e-04 -5.55551480e-04 -7.73753593e-04]\n",
            "\n",
            "POLYNOMIAL OF DEGREE 10\n",
            "Iteration 0 : 17684.06331646082\n",
            "Iteration 50 : 12689.086107773323\n",
            "Iteration 100 : 12463.416068747427\n",
            "Iteration 150 : 12395.88842927381\n",
            "Iteration 200 : 12359.681638250275\n",
            "Iteration 250 : 12339.499924096739\n",
            "Iteration 300 : 12328.035833501832\n",
            "Iteration 350 : 12321.354444381617\n",
            "Iteration 400 : 12317.324202370628\n",
            "Iteration 450 : 12314.785153152949\n",
            "Iteration 500 : 12313.101463249832\n",
            "Iteration 550 : 12311.92092017514\n",
            "Iteration 600 : 12311.045609086374\n",
            "Iteration 650 : 12310.36221865231\n",
            "Iteration 700 : 12309.804334939528\n",
            "Iteration 750 : 12309.331921521953\n",
            "Iteration 800 : 12308.920059530512\n",
            "Iteration 850 : 12308.552698726131\n",
            "Iteration 900 : 12308.219137269502\n",
            "Iteration 950 : 12307.912000289565\n",
            "Final training set RMSE : 12307.631589247554\n",
            "Final test set RMSE : 13014.957506622986\n",
            "[ 8.39453705e-02  3.42792476e-02  3.77591031e-02  2.55523876e-02\n",
            "  2.83576019e-02  2.68210086e-02  1.84456795e-02  1.90454932e-02\n",
            "  2.01377930e-02  1.78350175e-02  1.30885242e-02  1.24352993e-02\n",
            "  1.26851102e-02  1.29829357e-02  1.11324604e-02  9.19948859e-03\n",
            "  7.97530815e-03  7.71331748e-03  7.90919796e-03  7.90037470e-03\n",
            "  6.45370332e-03  6.40729589e-03  4.88744899e-03  4.21091262e-03\n",
            "  4.00415813e-03  4.27079166e-03  4.40211724e-03  3.33019412e-03\n",
            "  4.39543853e-03  2.70462060e-03  1.71397886e-03  1.34768661e-03\n",
            "  1.53536000e-03  1.87892563e-03  2.06115918e-03  1.31208225e-03\n",
            "  2.93073614e-03  1.12982125e-03 -4.68780772e-05 -6.21212837e-04\n",
            " -5.42794275e-04 -6.55060325e-05  4.28223501e-04  5.41286795e-04\n",
            "  4.57292799e-05  1.85050572e-03 -2.90684522e-05 -1.32639702e-03\n",
            " -2.09246250e-03 -2.13969813e-03 -1.69241711e-03 -9.67274749e-04\n",
            " -3.94642123e-04 -4.06183123e-04 -7.23088344e-04  1.04305510e-03\n",
            " -8.98131617e-04 -2.27963618e-03 -3.17187690e-03 -3.44634417e-03\n",
            " -3.01134065e-03 -2.32340718e-03 -1.35547854e-03 -8.00450343e-04\n",
            " -9.59683997e-04 -1.16929831e-03]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmNHmi5wG6cj"
      },
      "source": [
        "def stochastic_descent(X, Y, theta, alpha, num_iters, Y_max, Y_min):\n",
        "  m = X.shape[0]\n",
        "  c = 0\n",
        "\n",
        "  np.random.seed(seed=1)                    # choose one data point at a time\n",
        "  permutation = np.random.permutation(m)\n",
        "  X = X[permutation,:]\n",
        "  Y = Y[permutation]\n",
        "\n",
        "  for i in range(num_iters):\n",
        "    X_i = X[c:c+1,:]\n",
        "    Y_i = Y[c:c+1]\n",
        "    pred = X_i.dot(theta)\n",
        "    cost_der = np.dot(X_i.transpose(), (pred-Y_i))\n",
        "    theta = theta - alpha*cost_der         # update wights  \n",
        "\n",
        "    if i%50 == 0:                          # print error after every 50 iterations\n",
        "      Y_pred = X.dot(theta)\n",
        "      rmse = math.sqrt(np.mean(np.square(Y_pred - Y)))\n",
        "      rmse = rmse*(Y_max - Y_min) + Y_min\n",
        "      print(\"Iteration \" + str(i) + \" : \" + str(rmse))\n",
        "\n",
        "    if c+1 > m:                           # shuffle the dataset after all data points are processed\n",
        "      c = 0\n",
        "      permutation = np.random.permutation(m)\n",
        "      X = X[permutation,:]\n",
        "      Y = Y[permutation]\n",
        "    else:\n",
        "      c = c + 1\n",
        "    \n",
        "  \n",
        "  return theta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47xEI83HKnPu"
      },
      "source": [
        "def stochastic_descent_model(X_train, Y_train, X_test, Y_test, Y_train_max, Y_train_min, Y_test_max, Y_test_min, alpha, num_iters):\n",
        "  theta = np.zeros(X_train.shape[1])\n",
        "  theta = np.transpose(theta)\n",
        "  theta = stochastic_descent(X_train, Y_train, theta, alpha, num_iters, Y_train_max, Y_train_min) # calculate weights using stochastic gradient descent\n",
        "\n",
        "  Y_pred_train = X_train.dot(theta)\n",
        "  Y_pred_test = X_test.dot(theta)\n",
        "\n",
        "  rmse_train = math.sqrt(np.mean(np.square(Y_pred_train - Y_train)))       # calculate and print train and test errors\n",
        "  rmse_train = rmse_train*(Y_train_max - Y_train_min) + Y_train_min\n",
        "  rmse_test = math.sqrt(np.mean(np.square(Y_pred_test - Y_test)))\n",
        "  rmse_test = rmse_test*(Y_test_max - Y_test_min) + Y_test_min\n",
        "\n",
        "  print(\"Final training set RMSE : \" + str(rmse_train))\n",
        "  print(\"Final test set RMSE : \" + str(rmse_test))\n",
        "  print(\"Weights : \")\n",
        "  print(theta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuCixHV3MF4_",
        "outputId": "240591cd-63e6-4210-cf54-276517390bfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(10):                                      #apply polynomial regression for polynomials of degrees from 1 to 10\n",
        "  Xi = poly_features(X, i+1)\n",
        "  X_train, X_test, Y_train, Y_test = splitData(Xi, Y)       #split data into train and test sets           \n",
        "  X_train, Y_train, Y_train_max, Y_train_min = standardize(X_train, Y_train) #standardize train set\n",
        "  X_test, Y_test, Y_test_max, Y_test_min = standardize(X_test, Y_test) #stanardize test set\n",
        "  print(\"\\nPOLYNOMIAL OF DEGREE \" + str(i+1))\n",
        "  stochastic_descent_model(X_train, Y_train, X_test, Y_test, Y_train_max, Y_train_min, Y_test_max, Y_test_min, 0.01, 1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "POLYNOMIAL OF DEGREE 1\n",
            "Iteration 0 : 17964.325886550923\n",
            "Iteration 50 : 13443.860752733299\n",
            "Iteration 100 : 13102.503762711192\n",
            "Iteration 150 : 12774.32552122636\n",
            "Iteration 200 : 12614.262978700715\n",
            "Iteration 250 : 12581.046823085999\n",
            "Iteration 300 : 12552.386052240678\n",
            "Iteration 350 : 12550.128620902833\n",
            "Iteration 400 : 12538.138902566267\n",
            "Iteration 450 : 12621.665847898093\n",
            "Iteration 500 : 12557.952659175327\n",
            "Iteration 550 : 12529.644329214572\n",
            "Iteration 600 : 12501.731457715125\n",
            "Iteration 650 : 12513.949626005613\n",
            "Iteration 700 : 12564.954505670246\n",
            "Iteration 750 : 12516.203526011941\n",
            "Iteration 800 : 12479.841484817754\n",
            "Iteration 850 : 12464.036216271246\n",
            "Iteration 900 : 12475.27872602608\n",
            "Iteration 950 : 12452.691807530684\n",
            "Final training set RMSE : 12424.089498909932\n",
            "Final test set RMSE : 13000.588858942969\n",
            "Weights : \n",
            "[0.09966605 0.13225786 0.08382823]\n",
            "\n",
            "POLYNOMIAL OF DEGREE 2\n",
            "Iteration 0 : 17946.098789442447\n",
            "Iteration 50 : 12729.968071125331\n",
            "Iteration 100 : 12723.174584349155\n",
            "Iteration 150 : 12482.208423365713\n",
            "Iteration 200 : 12389.792266320579\n",
            "Iteration 250 : 12388.377411720709\n",
            "Iteration 300 : 12368.727141600777\n",
            "Iteration 350 : 12378.41397505695\n",
            "Iteration 400 : 12364.889102584073\n",
            "Iteration 450 : 12494.307747143106\n",
            "Iteration 500 : 12443.884610405661\n",
            "Iteration 550 : 12366.54335874103\n",
            "Iteration 600 : 12352.918143427301\n",
            "Iteration 650 : 12397.755165764554\n",
            "Iteration 700 : 12457.531678264028\n",
            "Iteration 750 : 12377.34910777169\n",
            "Iteration 800 : 12349.314813493467\n",
            "Iteration 850 : 12337.382004886373\n",
            "Iteration 900 : 12423.384516212873\n",
            "Iteration 950 : 12341.524392098076\n",
            "Final training set RMSE : 12321.98603471101\n",
            "Final test set RMSE : 12952.472416613264\n",
            "Weights : \n",
            "[0.07188302 0.0743129  0.05675235 0.06979591 0.0678337  0.0471923 ]\n",
            "\n",
            "POLYNOMIAL OF DEGREE 3\n",
            "Iteration 0 : 17932.411922400144\n",
            "Iteration 50 : 12406.364942579292\n",
            "Iteration 100 : 12575.647861304524\n",
            "Iteration 150 : 12372.471146524222\n",
            "Iteration 200 : 12320.65822141709\n",
            "Iteration 250 : 12325.522058228229\n",
            "Iteration 300 : 12333.793547876297\n",
            "Iteration 350 : 12328.530028582403\n",
            "Iteration 400 : 12316.259189895021\n",
            "Iteration 450 : 12481.51818673673\n",
            "Iteration 500 : 12448.17561441905\n",
            "Iteration 550 : 12319.8393242571\n",
            "Iteration 600 : 12318.84360197103\n",
            "Iteration 650 : 12376.337776014552\n",
            "Iteration 700 : 12440.62688528443\n",
            "Iteration 750 : 12341.421585930559\n",
            "Iteration 800 : 12318.640166520889\n",
            "Iteration 850 : 12310.849915028673\n",
            "Iteration 900 : 12488.535240363744\n",
            "Iteration 950 : 12320.664194284689\n",
            "Final training set RMSE : 12316.837139548254\n",
            "Final test set RMSE : 12983.926103318845\n",
            "Weights : \n",
            "[0.06720701 0.05014714 0.04522625 0.04538701 0.04695384 0.03656911\n",
            " 0.04066569 0.04173981 0.03984665 0.02867332]\n",
            "\n",
            "POLYNOMIAL OF DEGREE 4\n",
            "Iteration 0 : 17923.257012526745\n",
            "Iteration 50 : 12319.78085782495\n",
            "Iteration 100 : 12536.458417308342\n",
            "Iteration 150 : 12338.88632031806\n",
            "Iteration 200 : 12313.408295269166\n",
            "Iteration 250 : 12308.583308026258\n",
            "Iteration 300 : 12353.807867377296\n",
            "Iteration 350 : 12315.324798171854\n",
            "Iteration 400 : 12306.960064968996\n",
            "Iteration 450 : 12497.823966337484\n",
            "Iteration 500 : 12472.41619243906\n",
            "Iteration 550 : 12309.760164152578\n",
            "Iteration 600 : 12315.58470071988\n",
            "Iteration 650 : 12368.44590418333\n",
            "Iteration 700 : 12443.10048112469\n",
            "Iteration 750 : 12333.558321946422\n",
            "Iteration 800 : 12313.030949902834\n",
            "Iteration 850 : 12311.497753153619\n",
            "Iteration 900 : 12577.636376780772\n",
            "Iteration 950 : 12319.12564178246\n",
            "Final training set RMSE : 12338.862208514023\n",
            "Final test set RMSE : 13028.725833254322\n",
            "Weights : \n",
            "[0.06882081 0.04042926 0.04030834 0.03472728 0.03762738 0.03159932\n",
            " 0.02959471 0.03124569 0.03126927 0.02397999 0.02531745 0.0257563\n",
            " 0.02637924 0.02479086 0.01790674]\n",
            "\n",
            "POLYNOMIAL OF DEGREE 5\n",
            "Iteration 0 : 17917.307991277306\n",
            "Iteration 50 : 12350.813217500003\n",
            "Iteration 100 : 12544.756382763466\n",
            "Iteration 150 : 12336.290585572278\n",
            "Iteration 200 : 12330.18603125817\n",
            "Iteration 250 : 12308.95710795707\n",
            "Iteration 300 : 12393.240631699771\n",
            "Iteration 350 : 12313.626722485571\n",
            "Iteration 400 : 12308.843435706205\n",
            "Iteration 450 : 12520.999671047059\n",
            "Iteration 500 : 12491.049089081378\n",
            "Iteration 550 : 12311.103874219512\n",
            "Iteration 600 : 12319.379884856937\n",
            "Iteration 650 : 12359.810390583907\n",
            "Iteration 700 : 12450.130321163477\n",
            "Iteration 750 : 12333.57519587122\n",
            "Iteration 800 : 12313.864612693917\n",
            "Iteration 850 : 12322.721602214366\n",
            "Iteration 900 : 12665.847439175397\n",
            "Iteration 950 : 12321.928842764088\n",
            "Final training set RMSE : 12374.68763394292\n",
            "Final test set RMSE : 13077.191743158704\n",
            "Weights : \n",
            "[0.07125733 0.03669961 0.03818751 0.03010175 0.03347454 0.02922886\n",
            " 0.0243976  0.0262584  0.02711601 0.02159188 0.01983441 0.02046286\n",
            " 0.02152806 0.02093693 0.01565791 0.01632669 0.01623375 0.01726898\n",
            " 0.01784619 0.01637538 0.01131378]\n",
            "\n",
            "POLYNOMIAL OF DEGREE 6\n",
            "Iteration 0 : 17913.57637143968\n",
            "Iteration 50 : 12435.651069835423\n",
            "Iteration 100 : 12573.124377693743\n",
            "Iteration 150 : 12345.820621140614\n",
            "Iteration 200 : 12354.386338098906\n",
            "Iteration 250 : 12316.558126262988\n",
            "Iteration 300 : 12436.552710039081\n",
            "Iteration 350 : 12317.054633227743\n",
            "Iteration 400 : 12312.359918316673\n",
            "Iteration 450 : 12544.088012064003\n",
            "Iteration 500 : 12500.059426695712\n",
            "Iteration 550 : 12314.831039951168\n",
            "Iteration 600 : 12323.68037040412\n",
            "Iteration 650 : 12349.841273783548\n",
            "Iteration 700 : 12457.855669057544\n",
            "Iteration 750 : 12334.69318504031\n",
            "Iteration 800 : 12315.532973009227\n",
            "Iteration 850 : 12340.025037918624\n",
            "Iteration 900 : 12741.996028937328\n",
            "Iteration 950 : 12324.757245990622\n",
            "Final training set RMSE : 12419.521974251391\n",
            "Final test set RMSE : 13128.991109631692\n",
            "Weights : \n",
            "[0.07300003 0.0354425  0.0373484  0.02819301 0.03177783 0.02818296\n",
            " 0.02201721 0.0240283  0.02526708 0.02047306 0.01716049 0.0179404\n",
            " 0.01925501 0.01913374 0.01456449 0.01349847 0.01356014 0.0147371\n",
            " 0.01563182 0.01468283 0.01030209 0.0107832  0.01034245 0.01113476\n",
            " 0.01189286 0.01245253 0.01154097 0.00733446]\n",
            "\n",
            "POLYNOMIAL OF DEGREE 7\n",
            "Iteration 0 : 17911.253476490674\n",
            "Iteration 50 : 12541.453705977632\n",
            "Iteration 100 : 12608.2044899585\n",
            "Iteration 150 : 12358.675933185064\n",
            "Iteration 200 : 12378.376556626938\n",
            "Iteration 250 : 12327.409309336872\n",
            "Iteration 300 : 12477.548892260062\n",
            "Iteration 350 : 12324.584969916381\n",
            "Iteration 400 : 12314.621378782007\n",
            "Iteration 450 : 12565.014741581717\n",
            "Iteration 500 : 12502.063194468697\n",
            "Iteration 550 : 12318.411436313783\n",
            "Iteration 600 : 12328.342351789199\n",
            "Iteration 650 : 12340.46528621421\n",
            "Iteration 700 : 12465.350485237816\n",
            "Iteration 750 : 12334.92805071409\n",
            "Iteration 800 : 12316.611547317476\n",
            "Iteration 850 : 12362.728658062844\n",
            "Iteration 900 : 12803.208816180864\n",
            "Iteration 950 : 12326.423670114373\n",
            "Final training set RMSE : 12471.848584276437\n",
            "Final test set RMSE : 13184.079333396992\n",
            "Weights : \n",
            "[0.07394335 0.03508237 0.03705376 0.02741898 0.03116032 0.02776976\n",
            " 0.02092196 0.0230964  0.02453777 0.02000655 0.01584668 0.01679404\n",
            " 0.01828806 0.0183929  0.01409517 0.01205238 0.01227926 0.01359345\n",
            " 0.01467879 0.01397111 0.00986084 0.00926832 0.00898954 0.00989109\n",
            " 0.0108321  0.01158319 0.01087992 0.00693621 0.00723562 0.00656447\n",
            " 0.00695759 0.0079611  0.00913882 0.00939065 0.00877257 0.00495589]\n",
            "\n",
            "POLYNOMIAL OF DEGREE 8\n",
            "Iteration 0 : 17909.798762890707\n",
            "Iteration 50 : 12653.221730212452\n",
            "Iteration 100 : 12643.993796699879\n",
            "Iteration 150 : 12371.03814543357\n",
            "Iteration 200 : 12399.07395732136\n",
            "Iteration 250 : 12339.993925239685\n",
            "Iteration 300 : 12514.571983184032\n",
            "Iteration 350 : 12336.651992848338\n",
            "Iteration 400 : 12315.383467275264\n",
            "Iteration 450 : 12582.973520761163\n",
            "Iteration 500 : 12500.258069908217\n",
            "Iteration 550 : 12321.886723921976\n",
            "Iteration 600 : 12335.427185272767\n",
            "Iteration 650 : 12333.46690156952\n",
            "Iteration 700 : 12472.715383685707\n",
            "Iteration 750 : 12334.124205203207\n",
            "Iteration 800 : 12317.10803918658\n",
            "Iteration 850 : 12391.413090659313\n",
            "Iteration 900 : 12849.885292822566\n",
            "Iteration 950 : 12326.865353330712\n",
            "Final training set RMSE : 12531.56794074707\n",
            "Final test set RMSE : 13243.765554455098\n",
            "Weights : \n",
            "[0.07434022 0.03497885 0.036981   0.02707614 0.03098235 0.02764897\n",
            " 0.0203852  0.02274439 0.02432507 0.01986248 0.01517211 0.01630521\n",
            " 0.01795337 0.01817629 0.01394766 0.01129018 0.01169644 0.01315112\n",
            " 0.01436751 0.01376466 0.00972252 0.00845714 0.00834972 0.00937601\n",
            " 0.01045095 0.01131217 0.01069181 0.00681348 0.00640316 0.00589538\n",
            " 0.00640639 0.00752308 0.00880794 0.00916197 0.0086067  0.00485097\n",
            " 0.00491468 0.00407774 0.00419079 0.00520388 0.00635702 0.00786872\n",
            " 0.00782153 0.00722919 0.0035398 ]\n",
            "\n",
            "POLYNOMIAL OF DEGREE 9\n",
            "Iteration 0 : 17908.897836013533\n",
            "Iteration 50 : 12761.70959816833\n",
            "Iteration 100 : 12677.044339399596\n",
            "Iteration 150 : 12381.161431192884\n",
            "Iteration 200 : 12415.058671706904\n",
            "Iteration 250 : 12353.357092010398\n",
            "Iteration 300 : 12546.803252967846\n",
            "Iteration 350 : 12353.468171964263\n",
            "Iteration 400 : 12315.305204607432\n",
            "Iteration 450 : 12596.81292270361\n",
            "Iteration 500 : 12496.818195896129\n",
            "Iteration 550 : 12325.812613916425\n",
            "Iteration 600 : 12347.128054689414\n",
            "Iteration 650 : 12330.08392162539\n",
            "Iteration 700 : 12480.128068022736\n",
            "Iteration 750 : 12332.64834867044\n",
            "Iteration 800 : 12317.340673843391\n",
            "Iteration 850 : 12426.133196712393\n",
            "Iteration 900 : 12882.154396790505\n",
            "Iteration 950 : 12326.400043410855\n",
            "Final training set RMSE : 12596.567741680266\n",
            "Final test set RMSE : 13308.210392166637\n",
            "Weights : \n",
            "[0.07444863 0.03489958 0.03699765 0.02687106 0.0309627  0.02765952\n",
            " 0.02007672 0.02263343 0.02433465 0.0198708  0.01479005 0.01611708\n",
            " 0.01790786 0.01820271 0.01395699 0.01086221 0.01145345 0.01304793\n",
            " 0.01436511 0.01380259 0.00973491 0.00800522 0.0080724  0.00922857\n",
            " 0.01040989 0.01133863 0.01073884 0.00682985 0.00594334 0.00559991\n",
            " 0.00623195 0.00744825 0.00880887 0.0092072  0.00866166 0.00487144\n",
            " 0.00445821 0.00377597 0.00400142 0.0051028  0.00633277 0.00789976\n",
            " 0.00787989 0.00729137 0.00356403 0.00338871 0.00241869 0.00231349\n",
            " 0.00306085 0.00428953 0.00585753 0.00706087 0.00709569 0.00641821\n",
            " 0.00269284]\n",
            "\n",
            "POLYNOMIAL OF DEGREE 10\n",
            "Iteration 0 : 17908.33523060631\n",
            "Iteration 50 : 12863.9374728223\n",
            "Iteration 100 : 12706.46236542261\n",
            "Iteration 150 : 12388.636735886026\n",
            "Iteration 200 : 12426.407161074805\n",
            "Iteration 250 : 12366.979845749536\n",
            "Iteration 300 : 12575.197130745986\n",
            "Iteration 350 : 12375.281220053188\n",
            "Iteration 400 : 12315.261313355832\n",
            "Iteration 450 : 12606.049805056049\n",
            "Iteration 500 : 12492.903967420692\n",
            "Iteration 550 : 12330.562491171593\n",
            "Iteration 600 : 12365.164021925313\n",
            "Iteration 650 : 12330.682293974793\n",
            "Iteration 700 : 12487.84005450577\n",
            "Iteration 750 : 12330.868899243129\n",
            "Iteration 800 : 12317.59582925055\n",
            "Iteration 850 : 12467.088976275561\n",
            "Iteration 900 : 12901.91972071684\n",
            "Iteration 950 : 12325.34006763994\n",
            "Final training set RMSE : 12666.533389739761\n",
            "Final test set RMSE : 13377.09735625821\n",
            "Weights : \n",
            "[0.07445369 0.03477982 0.03704839 0.02669108 0.03098039 0.02772171\n",
            " 0.01985003 0.02260351 0.02441961 0.01994015 0.01453343 0.01604975\n",
            " 0.01797236 0.01832034 0.01402992 0.01059084 0.0113612  0.01308726\n",
            " 0.01448671 0.01393674 0.00980893 0.00773096 0.00796632 0.00924682\n",
            " 0.01051527 0.01148822 0.01088108 0.00690342 0.00567474 0.00548874\n",
            " 0.00623599 0.00753861 0.00895486 0.00936804 0.00880763 0.00494363\n",
            " 0.00420115 0.00366619 0.00399793 0.00518204 0.00646616 0.00807083\n",
            " 0.00804473 0.0074389  0.00363426 0.00314708 0.0023149  0.00230769\n",
            " 0.00313066 0.00441289 0.00601777 0.00723683 0.00726101 0.00656627\n",
            " 0.00276078 0.00239511 0.00130561 0.00101508 0.00149659 0.00266803\n",
            " 0.0041841  0.00602572 0.00683742 0.00684049 0.00603801 0.00217437]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOYfpnhWLdek"
      },
      "source": [
        "**Ridge Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS5L_uxjLjWG"
      },
      "source": [
        "def cost_function_ridge(theta, X, Y, lam):\n",
        "  m = X.shape[0]\n",
        "  pred = X.dot(theta)\n",
        "  cost = (1/(2*m))*np.sum(np.square(Y-pred)) + lam*(np.sum(np.square(theta)))\n",
        "  return cost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48DgIDrNL8_w"
      },
      "source": [
        "def gradient_descent_ridge(X, Y, theta, alpha, lam, num_iters, Y_max, Y_min):\n",
        "  m = X.shape[0]\n",
        "  for i in range(num_iters):\n",
        "    pred = X.dot(theta)\n",
        "    cost_der = (1/m)*np.dot(X.transpose(), (pred-Y)) \n",
        "    theta = theta*(1 - alpha*lam) - alpha*cost_der\n",
        "\n",
        "    if i%100 == 0:\n",
        "      Y_pred = X.dot(theta)\n",
        "      rmse = math.sqrt(np.mean(np.square(Y_pred - Y)))\n",
        "      rmse = rmse*(Y_max - Y_min) + Y_min\n",
        "      #print(color.BLUE+\"Iteration \" + str(i) + \" : \" + str(rmse))\n",
        "\n",
        "  return theta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6vxpLAtMJ5i"
      },
      "source": [
        "def gradient_descent_model_ridge(X, Y, alpha, lam, num_iters):\n",
        "  print(X)\n",
        "  X_train, X_test, Y_train, Y_test = splitData(X, Y)\n",
        "  X_train, Y_train, Y_train_max, Y_train_min = standardize(X_train, Y_train)\n",
        "  X_test, Y_test, Y_test_max, Y_test_min = standardize(X_test, Y_test)\n",
        "\n",
        "  theta = np.zeros(X_train.shape[1])\n",
        "  theta = np.transpose(theta)\n",
        "  theta = gradient_descent_ridge(X_train, Y_train, theta, alpha, lam, num_iters, Y_train_max, Y_train_min)\n",
        "\n",
        "  Y_pred_train = X_train.dot(theta)\n",
        "  Y_pred_test = X_test.dot(theta)\n",
        "\n",
        "  rmse_train = math.sqrt(np.mean(np.square(Y_pred_train - Y_train)))\n",
        "  rmse_train = rmse_train*(Y_train_max - Y_train_min) + Y_train_min\n",
        "  rmse_test = math.sqrt(np.mean(np.square(Y_pred_test - Y_test)))\n",
        "  rmse_test = rmse_test*(Y_test_max - Y_test_min) + Y_test_min\n",
        "\n",
        "  print(\"Final training set RMSE : \" + str(rmse_train))\n",
        "  print(\"Final test set RMSE : \" + str(rmse_test))\n",
        "  print(theta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zykbVOkkMkrl"
      },
      "source": [
        " def stochastic_descent_ridge(X, Y, theta, alpha, lam, num_iters, Y_max, Y_min):\n",
        "  m = X.shape[0]\n",
        "  c = 0\n",
        "\n",
        "  np.random.seed(seed=1) \n",
        "  permutation = np.random.permutation(m)\n",
        "  X = X[permutation,:]\n",
        "  Y = Y[permutation]\n",
        "\n",
        "  for i in range(num_iters):\n",
        "    X_i = X[c:c+1,:]\n",
        "    Y_i = Y[c:c+1]\n",
        "    pred = X_i.dot(theta)\n",
        "    cost_der = np.dot(X_i.transpose(), (pred-Y_i))\n",
        "    theta = theta*(1 - alpha*lam) - alpha*cost_der\n",
        "\n",
        "    if i%100 == 0:\n",
        "      Y_pred = X.dot(theta)\n",
        "      rmse = math.sqrt(np.mean(np.square(Y_pred - Y)))\n",
        "      rmse = rmse*(Y_max - Y_min) + Y_min\n",
        "      #print(\"Iteration \" + str(i) + \" : \" + str(rmse))\n",
        "\n",
        "    if c+1 > m:\n",
        "      c = 0\n",
        "      permutation = np.random.permutation(m)\n",
        "      X = X[permutation,:]\n",
        "      Y = Y[permutation]\n",
        "    else:\n",
        "      c = c + 1\n",
        "    \n",
        "  \n",
        "  return theta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fkk75A7OYzt"
      },
      "source": [
        "def stochastic_descent_model_ridge(X, Y, alpha, lam, num_iters):\n",
        "  X_train, X_test, Y_train, Y_test = splitData(X, Y)\n",
        "  X_train, Y_train, Y_train_max, Y_train_min = standardize(X_train, Y_train)\n",
        "  X_test, Y_test, Y_test_max, Y_test_min = standardize(X_test, Y_test)\n",
        "  \n",
        "  print(X_train.shape, Y_train.shape)\n",
        "  \n",
        "  theta = np.zeros(X_train.shape[1])\n",
        "  theta = np.transpose(theta)\n",
        "  theta = stochastic_descent_ridge(X_train, Y_train, theta, alpha, lam, num_iters, Y_train_max, Y_train_min)\n",
        "\n",
        "  Y_pred_train = X_train.dot(theta)\n",
        "  Y_pred_test = X_test.dot(theta)\n",
        "\n",
        "  rmse_train = math.sqrt(np.mean(np.square(Y_pred_train - Y_train)))\n",
        "  rmse_train = rmse_train*(Y_train_max - Y_train_min) + Y_train_min\n",
        "  rmse_test = math.sqrt(np.mean(np.square(Y_pred_test - Y_test)))\n",
        "  rmse_test = rmse_test*(Y_test_max - Y_test_min) + Y_test_min\n",
        "\n",
        "  print(\"Final training set RMSE : \" + str(rmse_train))\n",
        "  print(\"Final test set RMSE : \" + str(rmse_test))\n",
        "  print(theta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht705UlIctHL"
      },
      "source": [
        "**Lasso Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDWz30hfeGqg"
      },
      "source": [
        "def cost_function_lasso(theta, X, Y, lam):\n",
        "  m = X.shape[0]\n",
        "  pred = X.dot(theta)\n",
        "  cost = (1/(2*m))*np.sum(np.square(Y-pred)) + lam*(np.sum(np.abs(theta)))\n",
        "  return cost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBAEJX7ELbW5"
      },
      "source": [
        "def gradient_descent_lasso(X, Y, theta, alpha, lam, num_iters, Y_max, Y_min):\n",
        "  m, n = X.shape\n",
        "  for i in range(num_iters):\n",
        "    Y_pred = X.dot(theta)\n",
        "    for j in range(n):\n",
        "      if j == 0:\n",
        "        theta[j] = theta[j] + alpha*2*np.sum(Y - Y_pred) / m\n",
        "      else:\n",
        "        if theta[j] > 0 :\n",
        "          theta[j] = theta[j] - alpha*( - ( 2 * (X[:, j]).dot(Y - Y_pred)) + lam ) / m \n",
        "        else :\n",
        "          theta[j] = theta[j] - alpha*( - ( 2 * ( X[:, j] ).dot(Y - Y_pred))- lam ) / m   \n",
        "   \n",
        "    if i%100 == 0:\n",
        "      Y_pred = X.dot(theta)\n",
        "      rmse = math.sqrt(np.mean(np.square(Y_pred - Y)))\n",
        "      rmse = rmse*(Y_max - Y_min) + Y_min\n",
        "      #print(\"Iteration \" + str(i) + \" : \" + str(rmse))\n",
        "\n",
        "  return theta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFWqMkZlLtoQ"
      },
      "source": [
        "def gradient_descent_model_lasso(X, Y, alpha, num_iters):\n",
        "  X_train, X_test, Y_train, Y_test = splitData(X, Y)\n",
        "  X_train, Y_train, Y_train_max, Y_train_min = standardize(X_train, Y_train)\n",
        "  X_test, Y_test, Y_test_max, Y_test_min = standardize(X_test, Y_test)\n",
        "\n",
        "  theta = np.zeros(X_train.shape[1])\n",
        "  theta = np.transpose(theta)\n",
        "  theta = gradient_descent_lasso(X_train, Y_train, theta, alpha, 0.3, num_iters, Y_train_max, Y_train_min)\n",
        "\n",
        "  Y_pred_train = X_train.dot(theta)\n",
        "  Y_pred_test = X_test.dot(theta)\n",
        "\n",
        "  rmse_train = math.sqrt(np.mean(np.square(Y_pred_train - Y_train)))\n",
        "  rmse_train = rmse_train*(Y_train_max - Y_train_min) + Y_train_min\n",
        "  rmse_test = math.sqrt(np.mean(np.square(Y_pred_test - Y_test)))\n",
        "  rmse_test = rmse_test*(Y_test_max - Y_test_min) + Y_test_min\n",
        "\n",
        "  print(\"Final training set RMSE : \" + str(rmse_train))\n",
        "  print(\"Final test set RMSE : \" + str(rmse_test))\n",
        "  print(theta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WxwQIV9NsRM"
      },
      "source": [
        "def stochastic_descent_lasso(X, Y, theta, alpha, lam, num_iters, Y_max, Y_min):\n",
        "  m, n = X.shape\n",
        "  c = 0\n",
        "\n",
        "  np.random.seed(seed=1) \n",
        "  permutation = np.random.permutation(m)\n",
        "  X = X[permutation,:]\n",
        "  Y = Y[permutation]\n",
        "\n",
        "  for i in range(num_iters):\n",
        "    X_i = X[c:c+1,:]\n",
        "    Y_i = Y[c:c+1]\n",
        "\n",
        "    Y_pred = X_i.dot(theta)\n",
        "\n",
        "    for j in range(n):\n",
        "      if j == 0:\n",
        "        theta[j] = theta[j] + alpha*2*np.sum(Y_i - Y_pred) / m\n",
        "      else:\n",
        "        if theta[j] > 0 :\n",
        "          theta[j] = theta[j] - alpha*( - ( 2 * (X_i[:,j]).dot(Y_i - Y_pred)) + lam ) / m \n",
        "        else :\n",
        "          theta[j] = theta[j] - alpha*( - ( 2 * ( X_i[:,j] ).dot(Y_i - Y_pred))- lam ) / m \n",
        "\n",
        "    if i%100 == 0:\n",
        "      Y_pred = X.dot(theta)\n",
        "      rmse = math.sqrt(np.mean(np.square(Y_pred - Y)))\n",
        "      rmse = rmse*(Y_max - Y_min) + Y_min\n",
        "      #print(\"Iteration \" + str(i) + \" : \" + str(rmse))\n",
        "\n",
        "    if c+1 > m:\n",
        "      c = 0\n",
        "      permutation = np.random.permutation(m)\n",
        "      X = X[permutation,:]\n",
        "      Y = Y[permutation]\n",
        "    else:\n",
        "      c = c + 1\n",
        "    \n",
        "  \n",
        "  return theta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wziP9siubjZf"
      },
      "source": [
        "def stochastic_descent_model_lasso(X, Y, alpha, lam, num_iters):\n",
        "  X_train, X_test, Y_train, Y_test = splitData(X, Y)\n",
        "  X_train, Y_train, Y_train_max, Y_train_min = standardize(X_train, Y_train)\n",
        "  X_test, Y_test, Y_test_max, Y_test_min = standardize(X_test, Y_test)\n",
        "  \n",
        "  print(X_train.shape, Y_train.shape)\n",
        "  \n",
        "  theta = np.zeros(X_train.shape[1])\n",
        "  theta = np.transpose(theta)\n",
        "  theta = stochastic_descent_lasso(X_train, Y_train, theta, alpha, lam, num_iters, Y_train_max, Y_train_min)\n",
        "\n",
        "  Y_pred_train = X_train.dot(theta)\n",
        "  Y_pred_test = X_test.dot(theta)\n",
        "\n",
        "  rmse_train = math.sqrt(np.mean(np.square(Y_pred_train - Y_train)))\n",
        "  rmse_train = rmse_train*(Y_train_max - Y_train_min) + Y_train_min\n",
        "  rmse_test = math.sqrt(np.mean(np.square(Y_pred_test - Y_test)))\n",
        "  rmse_test = rmse_test*(Y_test_max - Y_test_min) + Y_test_min\n",
        "\n",
        "  print(\"Final training set RMSE : \" + str(rmse_train))\n",
        "  print(\"Final test set RMSE : \" + str(rmse_test))\n",
        "  print(theta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m85gDKJbv8P",
        "outputId": "4a631552-2de4-4364-c9fc-5c9ea501d3d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Xi = poly_features(X,5)\n",
        "stochastic_descent_model_lasso(Xi, Y, 0.1, 0.4, 10000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(932, 21) (932,)\n",
            "Iteration 0 : 18018.237956232486\n",
            "Iteration 100 : 17842.8477792137\n",
            "Iteration 200 : 17669.38354848155\n",
            "Iteration 300 : 17507.25738754931\n",
            "Iteration 400 : 17332.748011773958\n",
            "Iteration 500 : 17180.88440239027\n",
            "Iteration 600 : 17017.978454748165\n",
            "Iteration 700 : 16904.97713319927\n",
            "Iteration 800 : 16768.919417577275\n",
            "Iteration 900 : 16614.742478582873\n",
            "Iteration 1000 : 16457.193264556943\n",
            "Iteration 1100 : 16341.875858300602\n",
            "Iteration 1200 : 16204.546702921401\n",
            "Iteration 1300 : 16069.36218888299\n",
            "Iteration 1400 : 15979.276741736658\n",
            "Iteration 1500 : 15878.510721343077\n",
            "Iteration 1600 : 15792.600050144987\n",
            "Iteration 1700 : 15709.169895455445\n",
            "Iteration 1800 : 15594.743951896357\n",
            "Iteration 1900 : 15486.9713623519\n",
            "Iteration 2000 : 15384.170959468975\n",
            "Iteration 2100 : 15301.236298485628\n",
            "Iteration 2200 : 15236.545917608686\n",
            "Iteration 2300 : 15153.092053554119\n",
            "Iteration 2400 : 15061.118443197092\n",
            "Iteration 2500 : 14969.020634853014\n",
            "Iteration 2600 : 14889.915509145228\n",
            "Iteration 2700 : 14824.617922473228\n",
            "Iteration 2800 : 14754.462151587108\n",
            "Iteration 2900 : 14672.853591836185\n",
            "Iteration 3000 : 14624.68146751979\n",
            "Iteration 3100 : 14553.808762815946\n",
            "Iteration 3200 : 14482.05802452634\n",
            "Iteration 3300 : 14422.627420652172\n",
            "Iteration 3400 : 14371.838400436225\n",
            "Iteration 3500 : 14326.127095021218\n",
            "Iteration 3600 : 14270.301279405005\n",
            "Iteration 3700 : 14239.307795364279\n",
            "Iteration 3800 : 14201.935189167765\n",
            "Iteration 3900 : 14164.834948177091\n",
            "Iteration 4000 : 14136.819541018276\n",
            "Iteration 4100 : 14094.398334917494\n",
            "Iteration 4200 : 14055.769845293204\n",
            "Iteration 4300 : 14017.38826306504\n",
            "Iteration 4400 : 13988.668651785129\n",
            "Iteration 4500 : 13932.86235806106\n",
            "Iteration 4600 : 13881.104898912576\n",
            "Iteration 4700 : 13845.018731288701\n",
            "Iteration 4800 : 13808.604818013098\n",
            "Iteration 4900 : 13780.798773807084\n",
            "Iteration 5000 : 13757.530663111558\n",
            "Iteration 5100 : 13732.902665525797\n",
            "Iteration 5200 : 13700.081310893735\n",
            "Iteration 5300 : 13682.41350772209\n",
            "Iteration 5400 : 13657.523700728887\n",
            "Iteration 5500 : 13623.795703050902\n",
            "Iteration 5600 : 13602.1455579301\n",
            "Iteration 5700 : 13568.780443261609\n",
            "Iteration 5800 : 13563.304181874095\n",
            "Iteration 5900 : 13534.142676992264\n",
            "Iteration 6000 : 13509.911723504629\n",
            "Iteration 6100 : 13509.609849367196\n",
            "Iteration 6200 : 13489.83455686843\n",
            "Iteration 6300 : 13472.196449414616\n",
            "Iteration 6400 : 13459.844299239157\n",
            "Iteration 6500 : 13435.358988234537\n",
            "Iteration 6600 : 13411.894245566806\n",
            "Iteration 6700 : 13416.7374055784\n",
            "Iteration 6800 : 13393.49214804327\n",
            "Iteration 6900 : 13390.515615996272\n",
            "Iteration 7000 : 13377.804306021319\n",
            "Iteration 7100 : 13357.125208417092\n",
            "Iteration 7200 : 13345.059221266274\n",
            "Iteration 7300 : 13326.458646442074\n",
            "Iteration 7400 : 13314.56553478773\n",
            "Iteration 7500 : 13307.130236371557\n",
            "Iteration 7600 : 13304.075645099156\n",
            "Iteration 7700 : 13294.765197620167\n",
            "Iteration 7800 : 13279.800684468944\n",
            "Iteration 7900 : 13277.974619214556\n",
            "Iteration 8000 : 13267.481787282215\n",
            "Iteration 8100 : 13262.837192011386\n",
            "Iteration 8200 : 13255.599788410918\n",
            "Iteration 8300 : 13242.65656775306\n",
            "Iteration 8400 : 13232.252886523607\n",
            "Iteration 8500 : 13232.862087903848\n",
            "Iteration 8600 : 13221.66864050142\n",
            "Iteration 8700 : 13213.233174621111\n",
            "Iteration 8800 : 13205.352833712934\n",
            "Iteration 8900 : 13199.010658800053\n",
            "Iteration 9000 : 13199.599364457335\n",
            "Iteration 9100 : 13194.469095815153\n",
            "Iteration 9200 : 13185.471137581459\n",
            "Iteration 9300 : 13184.619031453223\n",
            "Iteration 9400 : 13178.937981241106\n",
            "Iteration 9500 : 13172.598224654765\n",
            "Iteration 9600 : 13165.69886708376\n",
            "Iteration 9700 : 13153.444285052628\n",
            "Iteration 9800 : 13161.943211950444\n",
            "Iteration 9900 : 13161.364926924141\n",
            "Final training set RMSE : 13149.93822497739\n",
            "Final test set RMSE : 13761.629420842299\n",
            "[ 1.68712061e-01  6.95025849e-05  5.39472809e-05  4.34543551e-06\n",
            "  5.25800736e-05  3.42492119e-05  5.04979890e-05  6.24581347e-05\n",
            "  2.10175609e-05  7.52246812e-05  3.36345589e-05  2.80069634e-05\n",
            "  3.27933041e-05  5.41579845e-05  4.74734566e-05 -8.50985646e-06\n",
            "  2.99371609e-05 -1.89707453e-05  2.25081091e-05  3.00269878e-05\n",
            "  4.96061835e-05]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaHX41GGSAX6"
      },
      "source": [
        "**Choosing the best regularization term for ridge regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpN07rIeb4bx"
      },
      "source": [
        "import random\n",
        "def choose_penalty_ridge_gd(num_penalty_values, X, Y, alpha, num_iters):\n",
        "  penalty_values = np.array([])\n",
        "  for i in range(num_penalty_values):\n",
        "    #print(random.uniform(0, 1))\n",
        "    penalty_values=np.append(penalty_values,np.array([random.uniform(0, 1)]))\n",
        "  #print(penalty_values) \n",
        "  #print(X)\n",
        "  #print(Y)\n",
        "  X_train, X_test, Y_train, Y_test, X_validation, Y_validation = splitDataReg(X, Y)\n",
        "  X_train, Y_train, Y_train_max, Y_train_min = standardize(X_train, Y_train)\n",
        "  X_test, Y_test, Y_test_max, Y_test_min = standardize(X_test, Y_test)\n",
        "  X_validation, Y_validation, Y_validation_max, Y_validation_min = standardize(X_validation, Y_validation)\n",
        "  min_penalty=-1\n",
        "  min_error=1e9\n",
        "  for i in penalty_values:\n",
        "    #print(\"added\")\n",
        "    theta = np.zeros(X_train.shape[1])\n",
        "    theta = np.transpose(theta)\n",
        "    theta = gradient_descent_ridge(X_train, Y_train, theta, alpha, i, num_iters, Y_train_max, Y_train_min)\n",
        "\n",
        "    Y_pred_train = X_train.dot(theta)\n",
        "    Y_pred_validation = X_validation.dot(theta)\n",
        "\n",
        "    rmse_train = math.sqrt(np.mean(np.square(Y_pred_train - Y_train)))\n",
        "    rmse_train = rmse_train*(Y_train_max - Y_train_min) + Y_train_min\n",
        "    rmse_validation = math.sqrt(np.mean(np.square(Y_pred_validation - Y_validation)))\n",
        "    rmse_validation = rmse_validation*(Y_validation_max - Y_validation_min) + Y_validation_min\n",
        "\n",
        "    print(color.BOLD+color.RED+\"Penalty : \",i,\" train error : \",rmse_train,\" validation error : \",rmse_validation,color.END)\n",
        "\n",
        "    if rmse_validation < min_error :\n",
        "      min_penalty = i\n",
        "      min_error = rmse_validation\n",
        "\n",
        "  theta = np.zeros(X_train.shape[1])\n",
        "  theta = np.transpose(theta)\n",
        "  theta = gradient_descent_ridge(X_train, Y_train, theta, alpha, min_penalty, num_iters, Y_train_max, Y_train_min)\n",
        "\n",
        "  Y_pred_train = X_train.dot(theta)\n",
        "  Y_pred_test = X_test.dot(theta)\n",
        "  Y_pred_validation = X_validation.dot(theta)\n",
        "\n",
        "  rmse_train = math.sqrt(np.mean(np.square(Y_pred_train - Y_train)))\n",
        "  rmse_train = rmse_train*(Y_train_max - Y_train_min) + Y_train_min\n",
        "  rmse_validation = math.sqrt(np.mean(np.square(Y_pred_validation - Y_validation)))\n",
        "  rmse_validation = rmse_validation*(Y_validation_max - Y_validation_min) + Y_validation_min\n",
        "  rmse_test = math.sqrt(np.mean(np.square(Y_pred_test - Y_test)))\n",
        "  rmse_test = rmse_test*(Y_test_max - Y_test_min) + Y_test_min\n",
        "\n",
        "  print(color.BOLD+color.RED+color.UNDERLINE+\"Best Penalty : \",min_penalty,\" Best train error : \",rmse_train,\" Best validation error : \",rmse_validation,\" Best testing error : \",rmse_test,color.END)\n",
        "  return min_penalty\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-QEvATRdrDA"
      },
      "source": [
        "def choose_penalty_ridge_model_gd(X,Y,num_penalty_values,alpha, num_iters):\n",
        "  for i in range(10):\n",
        "    Xi=poly_features(X, 1+i)\n",
        "    print(color.DARKCYAN+\"\\n \\nPolynomial degree : \", i+1,color.END+\"\\n\\n\")\n",
        "    lam = choose_penalty_ridge_gd(num_penalty_values, Xi, Y, alpha, num_iters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJjqqDvyGXr9",
        "outputId": "8a932cee-52ef-419d-dcb9-1144e4984184",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "choose_penalty_ridge_model_gd(X,Y,10,0.01, 10000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  1 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.3905388213554941  train error :  12874.43634939963  validation error :  13986.757207326315 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.646767920896396  train error :  13234.220313146712  validation error :  14394.817567395256 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7579376512307928  train error :  13387.844422238606  validation error :  14561.88761079304 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.40276646253945536  train error :  12891.425369212091  validation error :  14006.766448070568 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7155198899831008  train error :  13329.658877866881  validation error :  14498.979958786393 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6190077874509634  train error :  13195.36899248598  validation error :  14352.025349821966 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.15439158958118993  train error :  12558.724825590863  validation error :  13593.576158681377 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.015458344010213065  train error :  12341.512654617767  validation error :  13325.183402542412 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7498548295335531  train error :  13376.803410798084  validation error :  14549.982570603106 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.1323050075035913  train error :  12529.481703693093  validation error :  13555.217684645691 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.015458344010213065  Best train error :  12341.512654617767  Best validation error :  13325.183402542412  Best testing error :  12817.613556825718 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  2 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.6804325755107392  train error :  12885.456029499483  validation error :  14048.361263547915 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.5702667416129681  train error :  12767.476154380116  validation error :  13915.013741117678 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9743514637298338  train error :  13203.898795644209  validation error :  14394.988832048206 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.22733701246915705  train error :  12442.029115620788  validation error :  13516.31724424502 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.4541435001676247  train error :  12647.603775725865  validation error :  13775.10178349289 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9130134139083131  train error :  13137.93174506072  validation error :  14324.378742386722 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9731766750868346  train error :  13202.640610580327  validation error :  14393.646801912832 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9464264102285036  train error :  13173.933065504865  validation error :  14362.977491469952 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8586161988809311  train error :  13079.045210993296  validation error :  14260.8882182312 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.2128584524604823  train error :  12430.855752858219  validation error :  13501.08401724584 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.2128584524604823  Best train error :  12430.855752858219  Best validation error :  13501.08401724584  Best testing error :  13119.533248473397 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  3 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.5226719156182581  train error :  12569.446751684995  validation error :  13729.227995328181 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.5218581031544008  train error :  12568.807858383978  validation error :  13728.473231564974 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.0037737464563282197  train error :  12302.734327266777  validation error :  13362.108066731947 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.1984672068118305  train error :  12359.07005692784  validation error :  13458.338888763903 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.426033565709417  train error :  12496.555849553142  validation error :  13641.408562781698 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.23986379712250072  train error :  12379.406423186378  validation error :  13488.098958965056 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.31650407501880384  train error :  12423.095998908522  validation error :  13547.921532911096 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.09862116581440805  train error :  12321.338274278074  validation error :  13396.52301121634 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.25139089807262194  train error :  12385.500298560595  validation error :  13496.731167095617 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6290569362058314  train error :  12655.841256106207  validation error :  13829.464658648858 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.0037737464563282197  Best train error :  12302.734327266777  Best validation error :  13362.108066731947  Best testing error :  12753.02319161517 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  4 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.11774631631725363  train error :  12320.205088293958  validation error :  13429.73597454282 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.29219374161244116  train error :  12382.187388116829  validation error :  13528.39565484379 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8808446745432098  train error :  12765.813843826234  validation error :  13977.169080771162 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8248646122792812  train error :  12723.656485838976  validation error :  13931.308178966314 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8380556163968934  train error :  12733.540560261099  validation error :  13942.098501841454 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.33821293703923094  train error :  12404.441490981028  validation error :  13558.525233112898 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.17023073880805573  train error :  12334.597445089512  validation error :  13456.441293294498 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.3766649990054899  train error :  12424.548296408424  validation error :  13584.7320803077 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8351765501012457  train error :  12731.380461562238  validation error :  13939.742415562134 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.021558177635465414  train error :  12304.856712142442  validation error :  13387.827712223389 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.021558177635465414  Best train error :  12304.856712142442  Best validation error :  13387.827712223389  Best testing error :  12775.155831841754 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  5 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.4669489424953548  train error :  12461.794279343343  validation error :  13657.082044682615 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8449764306233224  train error :  12692.510717644287  validation error :  13919.078398381807 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7484477449001746  train error :  12629.295706764991  validation error :  13849.920160167938 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.789509693811231  train error :  12655.932584621118  validation error :  13879.221579214485 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.507738683941993  train error :  12483.95956633923  validation error :  13683.85073314235 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.5084510399243438  train error :  12484.354389311922  validation error :  13684.32261055163 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7955457674935165  train error :  12659.881604970118  validation error :  13883.544732695127 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.00822361195021104  train error :  12303.622746870366  validation error :  13387.232259513823 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9257587640507069  train error :  12746.784772812092  validation error :  13977.536780318982 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.2802010305547361  train error :  12373.81395088685  validation error :  13542.072605816189 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.00822361195021104  Best train error :  12303.622746870366  Best validation error :  13387.232259513823  Best testing error :  12761.634733148523 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  6 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.2102816163576846  train error :  12352.644374843925  validation error :  13524.722409061822 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.44184084487524855  train error :  12449.710581695239  validation error :  13660.835559591078 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.27083551728717536  train error :  12374.505434410958  validation error :  13559.442315711507 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.11221823325736557  train error :  12324.261020711594  validation error :  13468.290100543003 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.5231584446246171  train error :  12490.891061203063  validation error :  13711.00019264425 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6441872105638858  train error :  12556.966268382186  validation error :  13787.677375157125 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8936590048646733  train error :  12705.621798490889  validation error :  13950.975105342466 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9789465535444976  train error :  12758.924603553312  validation error :  14007.70113002866 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.06136515359108852  train error :  12313.502725070064  validation error :  13436.249107957934 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7411120678092258  train error :  12613.103734422657  validation error :  13850.468226816927 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.06136515359108852  Best train error :  12313.502725070064  Best validation error :  13436.249107957934  Best testing error :  12821.605430197413 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  7 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.592681690738043  train error :  12531.861584883933  validation error :  13773.101944175773 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.21676200745967888  train error :  12359.549665374036  validation error :  13544.630471253242 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.36627055172004497  train error :  12420.284615095507  validation error :  13635.270948010022 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.1817256634972827  train error :  12347.466221298715  validation error :  13522.90838319875 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7892001427661548  train error :  12640.58554186251  validation error :  13895.034823335254 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.35012958498494373  train error :  12413.123735714038  validation error :  13625.52867586294 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7190206924131739  train error :  12600.833727482423  validation error :  13851.278731360988 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.3344767300490141  train error :  12406.30389289167  validation error :  13616.082518832194 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6687951115173284  train error :  12572.972588092409  validation error :  13820.098165327776 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6803994554339544  train error :  12579.361821654491  validation error :  13827.29112733739 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.1817256634972827  Best train error :  12347.466221298715  Best validation error :  13522.90838319875  Best testing error :  12942.745544085416 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  8 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.25168118379582205  train error :  12376.640690704107  validation error :  13577.825488788525 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.5697989984971448  train error :  12526.150053688498  validation error :  13776.855024469956 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8615391245142306  train error :  12685.465823227509  validation error :  13955.310236209343 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.5205743504426444  train error :  12500.843548345028  validation error :  13746.58121282622 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.30925773666461787  train error :  12400.668713241106  validation error :  13614.851364766055 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9093928498439403  train error :  12712.657077040363  validation error :  13984.455414376935 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.0012927404473989101  train error :  12298.00298682153  validation error :  13357.583691176565 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.04666957301814845  train error :  12310.603052932365  validation error :  13425.207351936464 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.28513237906572064  train error :  12390.384151465396  validation error :  13599.438443588 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6174786139308585  train error :  12551.192443814954  validation error :  13806.115952334849 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.0012927404473989101  Best train error :  12298.00298682153  Best validation error :  13357.583691176565  Best testing error :  12762.425970921671 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  9 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.36724000586501293  train error :  12430.964886914066  validation error :  13662.168982365325 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.375832914230401  train error :  12435.030689546391  validation error :  13667.787216912278 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6921523749426066  train error :  12597.623188410713  validation error :  13866.921458637535 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.2035395614260218  train error :  12359.78352014738  validation error :  13550.706273961565 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8148477959615368  train error :  12664.95770298254  validation error :  13941.706876705024 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9497270858979183  train error :  12740.402770810397  validation error :  14022.884491338595 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.44698504617996426  train error :  12469.608980914913  validation error :  13713.738200220769 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.3308468669030582  train error :  12414.048200229574  validation error :  13638.176560344158 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8050878445202623  train error :  12659.548429920182  validation error :  13935.792516389154 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.42835352648163494  train error :  12460.408268303558  validation error :  13701.795107872429 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.2035395614260218  Best train error :  12359.78352014738  Best validation error :  13550.706273961565  Best testing error :  12966.260270350751 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  10 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.07975314113789722  train error :  12317.273592996282  validation error :  13450.506146047519 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8692474632904287  train error :  12701.153562632082  validation error :  13987.52082188007 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.40327295432478905  train error :  12451.655091396633  validation error :  13693.207078425026 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6128463398226206  train error :  12560.526981473895  validation error :  13829.45355798001 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7453063958160916  train error :  12632.558485094969  validation error :  13912.025864905772 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6202740623593805  train error :  12564.517833846867  validation error :  13834.143878050927 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.3028574832391221  train error :  12403.454260497863  validation error :  13624.19944021775 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6438756634315179  train error :  12577.241974115337  validation error :  13848.99658461533 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.26477180703016046  train error :  12386.25445222803  validation error :  13597.077953229007 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.45655612669902923  train error :  12478.493591685243  validation error :  13728.679607024755 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.07975314113789722  Best train error :  12317.273592996282  Best validation error :  13450.506146047519  Best testing error :  12836.50458694072 \u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVMCXZZ3PCww"
      },
      "source": [
        "def choose_penalty_ridge_sgd(num_penalty_values, X, Y, alpha, num_iters):\n",
        "  penalty_values = np.array([])\n",
        "  for i in range(num_penalty_values):\n",
        "    #print(random.uniform(0, 1))\n",
        "    penalty_values=np.append(penalty_values,np.array([random.uniform(0, 1)]))\n",
        "  #print(penalty_values) \n",
        "  #print(X)\n",
        "  #print(Y)\n",
        "  X_train, X_test, Y_train, Y_test, X_validation, Y_validation = splitDataReg(X, Y)\n",
        "  X_train, Y_train, Y_train_max, Y_train_min = standardize(X_train, Y_train)\n",
        "  X_test, Y_test, Y_test_max, Y_test_min = standardize(X_test, Y_test)\n",
        "  X_validation, Y_validation, Y_validation_max, Y_validation_min = standardize(X_validation, Y_validation)\n",
        "  min_penalty=-1\n",
        "  min_error=1e9\n",
        "  for i in penalty_values:\n",
        "    #print(\"added\")\n",
        "    theta = np.zeros(X_train.shape[1])\n",
        "    theta = np.transpose(theta)\n",
        "    theta = stochastic_descent_ridge(X_train, Y_train, theta, alpha, i, num_iters, Y_train_max, Y_train_min)\n",
        "\n",
        "    Y_pred_train = X_train.dot(theta)\n",
        "    Y_pred_validation = X_validation.dot(theta)\n",
        "\n",
        "    rmse_train = math.sqrt(np.mean(np.square(Y_pred_train - Y_train)))\n",
        "    rmse_train = rmse_train*(Y_train_max - Y_train_min) + Y_train_min\n",
        "    rmse_validation = math.sqrt(np.mean(np.square(Y_pred_validation - Y_validation)))\n",
        "    rmse_validation = rmse_validation*(Y_validation_max - Y_validation_min) + Y_validation_min\n",
        "\n",
        "    print(color.BOLD+color.RED+\"Penalty : \",i,\" train error : \",rmse_train,\" validation error : \",rmse_validation,color.END)\n",
        "\n",
        "    if rmse_validation < min_error :\n",
        "      min_penalty = i\n",
        "      min_error = rmse_validation\n",
        "\n",
        "  theta = np.zeros(X_train.shape[1])\n",
        "  theta = np.transpose(theta)\n",
        "  theta = stochastic_descent_ridge(X_train, Y_train, theta, alpha, min_penalty, num_iters, Y_train_max, Y_train_min)\n",
        "\n",
        "  Y_pred_train = X_train.dot(theta)\n",
        "  Y_pred_test = X_test.dot(theta)\n",
        "  Y_pred_validation = X_validation.dot(theta)\n",
        "\n",
        "  rmse_train = math.sqrt(np.mean(np.square(Y_pred_train - Y_train)))\n",
        "  rmse_train = rmse_train*(Y_train_max - Y_train_min) + Y_train_min\n",
        "  rmse_validation = math.sqrt(np.mean(np.square(Y_pred_validation - Y_validation)))\n",
        "  rmse_validation = rmse_validation*(Y_validation_max - Y_validation_min) + Y_validation_min\n",
        "  rmse_test = math.sqrt(np.mean(np.square(Y_pred_test - Y_test)))\n",
        "  rmse_test = rmse_test*(Y_test_max - Y_test_min) + Y_test_min\n",
        "\n",
        "  print(color.BOLD+color.RED+color.UNDERLINE+\"Best Penalty : \",min_penalty,\" Best train error : \",rmse_train,\" Best validation error : \",rmse_validation,\" Best testing error : \",rmse_test,color.END)\n",
        "  return min_penalty\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yApdUUXZPVRR"
      },
      "source": [
        "def choose_penalty_ridge_model_sgd(X,Y,num_penalty_values,alpha, num_iters):\n",
        "  for i in range(10):\n",
        "    Xi=poly_features(X, 1+i)\n",
        "    print(color.DARKCYAN+\"\\n \\nPolynomial degree : \", i+1,color.END+\"\\n\\n\")\n",
        "    lam = choose_penalty_ridge_sgd(num_penalty_values, Xi, Y, alpha, num_iters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pJTWZfRPd8I",
        "outputId": "c42706f1-0999-4167-a938-9a0233b26d43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "choose_penalty_ridge_model_sgd(X,Y,10,0.01, 10000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  1 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.7020962354230136  train error :  13046.780331018072  validation error :  14180.377318793107 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.11950899806090631  train error :  12477.1993255209  validation error :  13425.610891113156 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9464763163799624  train error :  13320.412171079734  validation error :  14486.277526661352 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7180883535933147  train error :  13064.81376150586  validation error :  14201.031087685835 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.5567118838177436  train error :  12884.472456809885  validation error :  13989.937794342834 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.10737358283603637  train error :  12467.436294075855  validation error :  13409.551674104063 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8582770021064852  train error :  13222.52873686813  validation error :  14378.48299402963 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.1747519870005042  train error :  12519.920471378144  validation error :  13495.933215554986 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8391015076517077  train error :  13201.065961196344  validation error :  14354.631086781685 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.504069399286694  train error :  12827.273121638345  validation error :  13920.311358307681 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.10737358283603637  Best train error :  12467.436294075855  Best validation error :  13409.551674104063  Best testing error :  12911.383067940811 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  2 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.48738740633914945  train error :  12485.031212468859  validation error :  13558.122958037204 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7008161985056085  train error :  12636.801898955788  validation error :  13754.22969018074 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9569172705231548  train error :  12845.769585610458  validation error :  14000.00299524245 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8330966158556067  train error :  12742.71400888171  validation error :  13880.991320768224 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.22344670209188122  train error :  12364.607334679127  validation error :  13358.627873690759 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.21430645807819027  train error :  12362.47484777076  validation error :  13353.231943108643 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.10944041427958573  train error :  12349.779158915333  validation error :  13301.852443388418 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.10973752199472964  train error :  12349.785528157463  validation error :  13301.967334531257 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9724946156616676  train error :  12858.880400410511  validation error :  14014.911447117482 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9037853659062216  train error :  12801.249395728879  validation error :  13949.012410728981 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.10944041427958573  Best train error :  12349.779158915333  Best validation error :  13301.852443388418  Best testing error :  12707.84376353357 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  3 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.2100877345719312  train error :  12315.272969489608  validation error :  13334.084969132924 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.41571594362764874  train error :  12341.10870803868  validation error :  13414.684837156032 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.02561599160219985  train error :  12356.535967181662  validation error :  13320.679673088158 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.37784374040194313  train error :  12331.627413808159  validation error :  13396.147430901528 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.23885806760503137  train error :  12314.718046423075  validation error :  13342.012259952264 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.707275905686316  train error :  12462.787607846944  validation error :  13592.533242034888 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.023380075974796855  train error :  12357.343810035713  validation error :  13321.057290332703 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.25501083917378575  train error :  12315.065231012008  validation error :  13347.009948467468 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.44023613277140106  train error :  12348.199611598055  validation error :  13427.401122850346 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.15386652042920523  train error :  12320.930717847794  validation error :  13322.533862635206 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.02561599160219985  Best train error :  12356.535967181662  Best validation error :  13320.679673088158  Best testing error :  12554.257147935588 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  4 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.6562970434194612  train error :  12377.109925300112  validation error :  13519.247063884693 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9552344951348486  train error :  12504.689836859276  validation error :  13682.218888135156 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.2708047706886545  train error :  12306.948933490314  validation error :  13376.372039515769 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7966886435329332  train error :  12431.88021384135  validation error :  13592.370969618385 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6486654949938434  train error :  12374.462924741674  validation error :  13515.50139808833 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.3269187390595776  train error :  12307.113146046131  validation error :  13389.748999870832 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.1506386047554381  train error :  12322.397274355992  validation error :  13359.270740104781 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7368762624870266  train error :  12407.230311107793  validation error :  13560.314953406169 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.5913261030872708  train error :  12355.84375014063  validation error :  13488.260442941622 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.56322905890834  train error :  12347.596089618666  validation error :  13475.540347119759 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.1506386047554381  Best train error :  12322.397274355992  Best validation error :  13359.270740104781  Best testing error :  12639.108376739112 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  5 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.9642574661620135  train error :  12468.633194194395  validation error :  13667.929241163789 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8523005497772091  train error :  12425.745642392107  validation error :  13614.998855617263 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8121956612292183  train error :  12411.502475816373  validation error :  13596.773922016648 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.065092701573216  train error :  12354.63228007274  validation error :  13388.186558532261 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.42501921399560627  train error :  12318.584685876214  validation error :  13451.261754554593 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9737087616390826  train error :  12472.441072073208  validation error :  13672.518019710902 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.30870176642047475  train error :  12313.092934537097  validation error :  13422.602325123858 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8144400015863863  train error :  12412.28223158985  validation error :  13597.78226035225 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.4994474109376844  train error :  12328.597478104208  validation error :  13473.860149298822 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.2842920937887382  train error :  12313.733949226757  validation error :  13417.69934174899 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.065092701573216  Best train error :  12354.63228007274  Best validation error :  13388.186558532261  Best testing error :  12571.53540914129 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  6 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.013666413776350583  train error :  12374.954609197484  validation error :  13372.002098464935 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8202306282490464  train error :  12411.745858016091  validation error :  13619.647245927963 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6822915976375087  train error :  12373.879027833842  validation error :  13567.612892224064 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.08500171925360589  train error :  12352.876073123773  validation error :  13411.643688039165 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.17930627796600795  train error :  12333.238839369073  validation error :  13431.582391853732 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6262330092913687  train error :  12360.935466241508  validation error :  13548.002569399918 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9862810656602385  train error :  12466.455342920419  validation error :  13688.01830765364 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.35388916891984146  train error :  12324.71194163884  validation error :  13468.428254447166 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8018652351164192  train error :  12406.260852735724  validation error :  13612.439573400452 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.17694521140993824  train error :  12333.582191530983  validation error :  13431.12843068235 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.013666413776350583  Best train error :  12374.954609197484  Best validation error :  13372.002098464935  Best testing error :  12524.386584169426 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  7 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.9584591905431483  train error :  12460.193891914118  validation error :  13697.592921998828 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9306878125119652  train error :  12451.5144282904  validation error :  13686.86381391818 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.047888043322065865  train error :  12365.564588593215  validation error :  13402.688486384352 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9260438139522655  train error :  12450.082272774247  validation error :  13685.080262651598 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8934557686222978  train error :  12440.193884888096  validation error :  13672.653662930039 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8753664706613585  train error :  12434.83102880208  validation error :  13665.825365411318 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.45170878156273453  train error :  12343.7395652118  validation error :  13523.99754963234 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8768492026830185  train error :  12435.267120083312  validation error :  13666.383137791416 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8797244844189082  train error :  12436.11456838747  validation error :  13667.465745579757 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.17680598228402966  train error :  12339.951486391332  validation error :  13450.676984393618 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.047888043322065865  Best train error :  12365.564588593215  Best validation error :  13402.688486384352  Best testing error :  12555.969190321834 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  8 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.9112770931063269  train error :  12454.656520488368  validation error :  13702.99695758105 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.061262181930983095  train error :  12363.03100444519  validation error :  13410.281282705311 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6334296297277882  train error :  12384.84549986853  validation error :  13605.18646617581 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.13014351966826476  train error :  12349.569039379527  validation error :  13443.826900333414 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.17448329631474924  train error :  12344.523034761452  validation error :  13460.02989009395 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8847861225454554  train error :  12447.079118417472  validation error :  13693.283224865743 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.3581745409572119  train error :  12344.739004509076  validation error :  13517.77158467457 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.22726855449823802  train error :  12341.516372574486  validation error :  13477.428968581891 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8335520181882732  train error :  12432.912719033673  validation error :  13674.709865715708 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.49200461377509386  train error :  12359.652212808856  validation error :  13559.209620681875 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.061262181930983095  Best train error :  12363.03100444519  Best validation error :  13410.281282705311  Best testing error :  12564.859764356512 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  9 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.6682135405529553  train error :  12402.271953364938  validation error :  13636.106760696232 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6086402006178477  train error :  12389.5593006023  validation error :  13615.356234632754 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9577318395779918  train error :  12477.619086888448  validation error :  13740.207585546732 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6427997108778365  train error :  12396.709083341177  validation error :  13627.227347813476 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6428828228307565  train error :  12396.726944325952  validation error :  13627.256319320048 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7771134097308613  train error :  12428.234138755284  validation error :  13674.635712165464 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.12186754505308717  train error :  12352.992946445487  validation error :  13440.80459704115 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.5954349658334179  train error :  12386.900728009765  validation error :  13610.786038768836 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.582438742093886  train error :  12384.343854291841  validation error :  13606.298003004544 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.38892636520352897  train error :  12354.461609936177  validation error :  13540.224638556396 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.12186754505308717  Best train error :  12352.992946445487  Best validation error :  13440.80459704115  Best testing error :  12616.901466210045 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  10 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.14639788855608582  train error :  12352.566697930091  validation error :  13450.161223844845 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.2830381278862779  train error :  12350.51426470786  validation error :  13506.989495590653 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.01391212712266332  train error :  12379.86141553465  validation error :  13352.607406357045 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6757807356560929  train error :  12412.287392157868  validation error :  13652.280567102012 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.07329209667057135  train error :  12364.089291749284  validation error :  13410.860369117088 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.5435164445326802  train error :  12384.343654310705  validation error :  13603.92939539744 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.5077141380938621  train error :  12377.787529166018  validation error :  13590.833164195237 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.5928699143971007  train error :  12394.128703589724  validation error :  13621.96436986088 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.2903123784336815  train error :  12350.912036204236  validation error :  13509.804153437373 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.0014680602522822994  train error :  12383.917722251934  validation error :  13329.995002021047 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.0014680602522822994  Best train error :  12383.917722251934  Best validation error :  13329.995002021047  Best testing error :  12488.547889582509 \u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPz6OrucLn2t"
      },
      "source": [
        "**Choosing the best regularization term for lasso regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-vR6_r6LGFK"
      },
      "source": [
        "def choose_penalty_lasso_gd(num_penalty_values, X, Y, alpha, num_iters):\n",
        "  penalty_values = np.array([])\n",
        "\n",
        "  for i in range(num_penalty_values):\n",
        "    penalty_values=np.append(penalty_values,np.array([random.uniform(0, 1)]))\n",
        " \n",
        "  X_train, X_test, Y_train, Y_test, X_validation, Y_validation = splitDataReg(X, Y)\n",
        "  X_train, Y_train, Y_train_max, Y_train_min = standardize(X_train, Y_train)\n",
        "  X_test, Y_test, Y_test_max, Y_test_min = standardize(X_test, Y_test)\n",
        "  X_validation, Y_validation, Y_validation_max, Y_validation_min = standardize(X_validation, Y_validation)\n",
        "\n",
        "  min_penalty=-1\n",
        "  min_error=1e9\n",
        "\n",
        "  for i in penalty_values:\n",
        "    #print(\"added\")\n",
        "    theta = np.zeros(X_train.shape[1])\n",
        "    theta = np.transpose(theta)\n",
        "    theta = gradient_descent_lasso(X_train, Y_train, theta, alpha, i, num_iters, Y_train_max, Y_train_min)\n",
        "\n",
        "    Y_pred_train = X_train.dot(theta)\n",
        "    Y_pred_validation = X_validation.dot(theta)\n",
        "\n",
        "    rmse_train = math.sqrt(np.mean(np.square(Y_pred_train - Y_train)))\n",
        "    rmse_train = rmse_train*(Y_train_max - Y_train_min) + Y_train_min\n",
        "    rmse_validation = math.sqrt(np.mean(np.square(Y_pred_validation - Y_validation)))\n",
        "    rmse_validation = rmse_validation*(Y_validation_max - Y_validation_min) + Y_validation_min\n",
        "\n",
        "    print(color.BOLD+color.RED+\"Penalty : \",i,\" train error : \",rmse_train,\" validation error : \",rmse_validation,color.END)\n",
        "\n",
        "    if rmse_validation < min_error :\n",
        "      min_penalty = i\n",
        "      min_error = rmse_validation\n",
        "\n",
        "  theta = np.zeros(X_train.shape[1])\n",
        "  theta = np.transpose(theta)\n",
        "  theta = gradient_descent_lasso(X_train, Y_train, theta, alpha, min_penalty, num_iters, Y_train_max, Y_train_min)\n",
        "\n",
        "  Y_pred_train = X_train.dot(theta)\n",
        "  Y_pred_test = X_test.dot(theta)\n",
        "  Y_pred_validation = X_validation.dot(theta)\n",
        "\n",
        "  rmse_train = math.sqrt(np.mean(np.square(Y_pred_train - Y_train)))\n",
        "  rmse_train = rmse_train*(Y_train_max - Y_train_min) + Y_train_min\n",
        "  rmse_validation = math.sqrt(np.mean(np.square(Y_pred_validation - Y_validation)))\n",
        "  rmse_validation = rmse_validation*(Y_validation_max - Y_validation_min) + Y_validation_min\n",
        "  rmse_test = math.sqrt(np.mean(np.square(Y_pred_test - Y_test)))\n",
        "  rmse_test = rmse_test*(Y_test_max - Y_test_min) + Y_test_min\n",
        "\n",
        "  print(color.BOLD+color.RED+color.UNDERLINE+\"Best Penalty : \",min_penalty,\" Best train error : \",rmse_train,\" Best validation error : \",rmse_validation,\" Best testing error : \",rmse_test,color.END)\n",
        "  return min_penalty"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GN3Qs3fMcnO"
      },
      "source": [
        "def choose_penalty_lasso_model_gd(X,Y,num_penalty_values,alpha, num_iters):\n",
        "  for i in range(10):\n",
        "    Xi=poly_features(X, 1+i)\n",
        "    print(color.DARKCYAN+\"\\n \\nPolynomial degree : \", i+1,color.END+\"\\n\\n\")\n",
        "    lam = choose_penalty_lasso_gd(num_penalty_values, Xi, Y, alpha, num_iters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQnO_rMnMmS5",
        "outputId": "dac61454-31e9-4b2b-bd33-ffecfe785ab4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "choose_penalty_lasso_model_gd(X,Y,10,0.01, 1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  1 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.875341771445816  train error :  12376.4770874824  validation error :  13338.758170580131 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8459722484724913  train error :  12376.173958747906  validation error :  13338.472607153963 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.36600560730278364  train error :  12371.344004553794  validation error :  13333.921312204136 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.773688460802014  train error :  12375.43162531538  validation error :  13337.773252983165 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.21440920839879207  train error :  12369.867018643215  validation error :  13332.52904537417 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.04695617846033018  train error :  12368.262650819092  validation error :  13331.016415897999 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7788340508429864  train error :  12375.484294016302  validation error :  13337.822874024196 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.20715511289570965  train error :  12369.796927428997  validation error :  13332.462968366848 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6351973100121984  train error :  12374.024151059632  validation error :  13336.447121805455 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.09861331188166855  train error :  12368.754542216158  validation error :  13331.480213563495 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.04695617846033018  Best train error :  12368.262650819092  Best validation error :  13331.016415897999  Best testing error :  12817.886109484878 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  2 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.10075044942336375  train error :  12313.66801357708  validation error :  13322.873811413636 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9065732916475037  train error :  12317.906583675356  validation error :  13324.734276455803 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8019499433093861  train error :  12317.28193546839  validation error :  13324.420975149405 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.5043370453150925  train error :  12315.626331459567  validation error :  13323.64682424672 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.4106909803975355  train error :  12315.142512382254  validation error :  13323.43906743757 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.05464566607764565  train error :  12313.465319517381  validation error :  13322.805785637904 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7498653380174362  train error :  12316.9792349716  validation error :  13324.272986044449 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6766597650397532  train error :  12316.563077563744  validation error :  13324.073955075786 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.5668270164746589  train error :  12315.95907193356  validation error :  13323.795003424091 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.2777957836565803  train error :  12314.486429532884  validation error :  13323.173683318211 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.05464566607764565  Best train error :  12313.465319517381  Best validation error :  13322.805785637904  Best testing error :  12765.345324176436 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  3 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.0845710231645117  train error :  12304.865278854404  validation error :  13355.379197918319 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.10127210433437794  train error :  12304.896169940266  validation error :  13355.32065687206 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.5653801914546465  train error :  12306.069157867087  validation error :  13353.995914003846 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9710168923821021  train error :  12307.591567976495  validation error :  13353.31572401026 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6674693313608211  train error :  12306.408646712876  validation error :  13353.7827664555 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7545271582080544  train error :  12306.721354681824  validation error :  13353.623297856866 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.1901206314574969  train error :  12305.073728532536  validation error :  13355.021915882462 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.28272383900056386  train error :  12305.282477368364  validation error :  13354.733294499105 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.4075082869598641  train error :  12305.60200730524  validation error :  13354.381092955702 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.23094351995446327  train error :  12305.162772950413  validation error :  13354.891819673781 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.9710168923821021  Best train error :  12307.591567976495  Best validation error :  13353.31572401026  Best testing error :  12768.964551704228 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  4 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.6724867629985618  train error :  12306.143936095461  validation error :  13376.91221480256 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6689966518351397  train error :  12306.134499449325  validation error :  13376.93200411467 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6929842251791323  train error :  12306.200228120066  validation error :  13376.796841056788 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.49271848905716786  train error :  12305.713980634695  validation error :  13377.986240627766 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7680069069433704  train error :  12306.418949280811  validation error :  13376.386938140735 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8590197580990305  train error :  12306.71103989729  validation error :  13375.915769097608 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.37497793579763805  train error :  12305.494401047563  validation error :  13378.750159742664 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.49226046998824535  train error :  12305.71303133763  validation error :  13377.989119591039 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.2077994314006103  train error :  12305.266967937869  validation error :  13379.917057972953 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.12632793346509885  train error :  12305.192005941059  validation error :  13380.520685038435 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.8590197580990305  Best train error :  12306.71103989729  Best validation error :  13375.915769097608  Best testing error :  12769.570616222052 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  5 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.2821347657307912  train error :  12306.996183859777  validation error :  13392.818693908663 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.5249484726285155  train error :  12307.324104736927  validation error :  13390.357412086783 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.4319697303359703  train error :  12307.169125735365  validation error :  13391.270524517711 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.46587889229892254  train error :  12307.221417818108  validation error :  13390.93329137286 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.5213184358436879  train error :  12307.317369419174  validation error :  13390.392377612514 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8072438873945543  train error :  12308.018268942174  validation error :  13387.80849048196 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.45677373808322963  train error :  12307.206899779312  validation error :  13391.023367770373 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.4324257801633594  train error :  12307.169796812741  validation error :  13391.265956852418 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.2691963923486457  train error :  12306.985696353237  validation error :  13392.956818061833 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.4695954865453693  train error :  12307.227444473969  validation error :  13390.896623933912 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.8072438873945543  Best train error :  12308.018268942174  Best validation error :  13387.80849048196  Best testing error :  12774.230988316725 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  6 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.4603984800755674  train error :  12307.963638833746  validation error :  13393.061165961039 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.00353452575862645  train error :  12307.798146435654  validation error :  13399.538912208818 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9611952879918535  train error :  12309.31074812557  validation error :  13387.468863748649 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7238845577143579  train error :  12308.535426694705  validation error :  13389.899333054464 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6152336260378218  train error :  12308.261366515084  validation error :  13391.167528271726 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.448253546569058  train error :  12307.944909947606  validation error :  13393.213643827314 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.2953976907048066  train error :  12307.765338400814  validation error :  13395.184875436446 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.770291223682967  train error :  12308.668982765457  validation error :  13389.37279642769 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.03659967710381673  train error :  12307.772133535997  validation error :  13399.021260135587 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.5598444184437913  train error :  12308.142306681399  validation error :  13391.83450449965 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.9611952879918535  Best train error :  12309.31074812557  Best validation error :  13387.468863748649  Best testing error :  12777.450252258248 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  7 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.7489522350544062  train error :  12308.630061070608  validation error :  13388.326094644606 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.12034852452679823  train error :  12307.551557857218  validation error :  13395.212576178737 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.055076069828634  train error :  12307.509847115496  validation error :  13395.63993331822 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.2522476866711575  train error :  12307.689789149665  validation error :  13394.174670387007 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9718966006156333  train error :  12309.386646363793  validation error :  13386.118962046901 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.5628548812836489  train error :  12308.15717071607  validation error :  13390.45825012111 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.341360265891559  train error :  12307.795245991825  validation error :  13393.112862384922 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9128338954974807  train error :  12309.164665825732  validation error :  13386.675089231956 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8679640146165171  train error :  12309.0066638972  validation error :  13387.098926982891 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7543918576912849  train error :  12308.645349729311  validation error :  13388.27030164921 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.9718966006156333  Best train error :  12309.386646363793  Best validation error :  13386.118962046901  Best testing error :  12777.008920686361 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  8 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.053724517202933475  train error :  12306.643922318879  validation error :  13390.12204972231 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.588442573566606  train error :  12308.16532459231  validation error :  13389.463670419256 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9541433478649468  train error :  12309.28138962088  validation error :  13385.688480123863 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8574894667303656  train error :  12308.930322229011  validation error :  13386.520485252053 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.24789003219126982  train error :  12307.490790976779  validation error :  13393.08473923165 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.31641073430442  train error :  12307.686919459155  validation error :  13392.706529023095 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.5616395011678841  train error :  12308.105975220591  validation error :  13389.772982685818 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.44033811232563724  train error :  12307.87687345613  validation error :  13391.21761416421 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.07422621523556316  train error :  12306.719954432221  validation error :  13390.436979080932 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.47665457673632494  train error :  12307.938461283533  validation error :  13390.777138850905 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.9541433478649468  Best train error :  12309.28138962088  Best validation error :  13385.688480123863  Best testing error :  12776.614434720193 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  9 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.27887586589003277  train error :  12307.209661599742  validation error :  13391.237923567774 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.10853946783569768  train error :  12305.863917492936  validation error :  13385.767752430524 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9402461564949143  train error :  12309.200105046704  validation error :  13385.528619298206 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9416726776802574  train error :  12309.209476273  validation error :  13385.497583992468 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.29126147055388574  train error :  12307.293865703372  validation error :  13391.411149608428 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6214464236184485  train error :  12308.205962295071  validation error :  13388.709986226966 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.17006731592087587  train error :  12306.356071047085  validation error :  13388.197930299131 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.30873437711376106  train error :  12307.400158179025  validation error :  13391.58943902191 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.3053630846034534  train error :  12307.380252689578  validation error :  13391.55218890928 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.41902255471752015  train error :  12307.804292456933  validation error :  13391.098459864788 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.9416726776802574  Best train error :  12309.209476273  Best validation error :  13385.497583992468  Best testing error :  12776.4567842438 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  10 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.689458985681869  train error :  12308.364512552309  validation error :  13387.778614555784 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.13884979808376263  train error :  12305.033862522785  validation error :  13382.699600199556 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.26000112978767886  train error :  12306.321126872104  validation error :  13388.039046854503 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.802046898810657  train error :  12308.700542736484  validation error :  13386.586703295321 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9250907597638226  train error :  12309.129134471896  validation error :  13385.499012195236 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9806009118057861  train error :  12309.34777328957  validation error :  13385.01148257451 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6070404090507904  train error :  12308.153592746256  validation error :  13388.753937602996 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9831378906411171  train error :  12309.35423877371  validation error :  13385.01549562661 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.30283136808831734  train error :  12306.767640597713  validation error :  13389.454100242652 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8910178521998846  train error :  12309.002913619714  validation error :  13385.80210296551 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.13884979808376263  Best train error :  12305.033862522785  Best validation error :  13382.699600199556  Best testing error :  12753.723250764386 \u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNn5g3KPP5F8"
      },
      "source": [
        "def choose_penalty_lasso_sgd(num_penalty_values, X, Y, alpha, num_iters):\n",
        "  penalty_values = np.array([])\n",
        "\n",
        "  for i in range(num_penalty_values):\n",
        "    penalty_values=np.append(penalty_values,np.array([random.uniform(0, 1)]))\n",
        " \n",
        "  X_train, X_test, Y_train, Y_test, X_validation, Y_validation = splitDataReg(X, Y)\n",
        "  X_train, Y_train, Y_train_max, Y_train_min = standardize(X_train, Y_train)\n",
        "  X_test, Y_test, Y_test_max, Y_test_min = standardize(X_test, Y_test)\n",
        "  X_validation, Y_validation, Y_validation_max, Y_validation_min = standardize(X_validation, Y_validation)\n",
        "\n",
        "  min_penalty=-1\n",
        "  min_error=1e9\n",
        "\n",
        "  for i in penalty_values:\n",
        "    #print(\"added\")\n",
        "    theta = np.zeros(X_train.shape[1])\n",
        "    theta = np.transpose(theta)\n",
        "    theta = stochastic_descent_lasso(X_train, Y_train, theta, alpha, i, num_iters, Y_train_max, Y_train_min)\n",
        "\n",
        "    Y_pred_train = X_train.dot(theta)\n",
        "    Y_pred_validation = X_validation.dot(theta)\n",
        "\n",
        "    rmse_train = math.sqrt(np.mean(np.square(Y_pred_train - Y_train)))\n",
        "    rmse_train = rmse_train*(Y_train_max - Y_train_min) + Y_train_min\n",
        "    rmse_validation = math.sqrt(np.mean(np.square(Y_pred_validation - Y_validation)))\n",
        "    rmse_validation = rmse_validation*(Y_validation_max - Y_validation_min) + Y_validation_min\n",
        "\n",
        "    print(color.BOLD+color.RED+\"Penalty : \",i,\" train error : \",rmse_train,\" validation error : \",rmse_validation,color.END)\n",
        "\n",
        "    if rmse_validation < min_error :\n",
        "      min_penalty = i\n",
        "      min_error = rmse_validation\n",
        "\n",
        "  theta = np.zeros(X_train.shape[1])\n",
        "  theta = np.transpose(theta)\n",
        "  theta = stochastic_descent_lasso(X_train, Y_train, theta, alpha, min_penalty, num_iters, Y_train_max, Y_train_min)\n",
        "\n",
        "  Y_pred_train = X_train.dot(theta)\n",
        "  Y_pred_test = X_test.dot(theta)\n",
        "  Y_pred_validation = X_validation.dot(theta)\n",
        "\n",
        "  rmse_train = math.sqrt(np.mean(np.square(Y_pred_train - Y_train)))\n",
        "  rmse_train = rmse_train*(Y_train_max - Y_train_min) + Y_train_min\n",
        "  rmse_validation = math.sqrt(np.mean(np.square(Y_pred_validation - Y_validation)))\n",
        "  rmse_validation = rmse_validation*(Y_validation_max - Y_validation_min) + Y_validation_min\n",
        "  rmse_test = math.sqrt(np.mean(np.square(Y_pred_test - Y_test)))\n",
        "  rmse_test = rmse_test*(Y_test_max - Y_test_min) + Y_test_min\n",
        "\n",
        "  print(color.BOLD+color.RED+color.UNDERLINE+\"Best Penalty : \",min_penalty,\" Best train error : \",rmse_train,\" Best validation error : \",rmse_validation,\" Best testing error : \",rmse_test,color.END)\n",
        "  return min_penalty"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqUuzNjkQOI9"
      },
      "source": [
        "def choose_penalty_lasso_model_sgd(X,Y,num_penalty_values,alpha, num_iters):\n",
        "  for i in range(10):\n",
        "    Xi=poly_features(X, 1+i)\n",
        "    print(color.DARKCYAN+\"\\n \\nPolynomial degree : \", i+1,color.END+\"\\n\\n\")\n",
        "    lam = choose_penalty_lasso_sgd(num_penalty_values, Xi, Y, alpha, num_iters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q6BaReEQSoZ",
        "outputId": "4941e2f4-aef2-47c1-aa74-2efd09dbd625",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "choose_penalty_lasso_model_sgd(X,Y,10,0.1, 10000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  1 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.9167774567305519  train error :  13154.015259179938  validation error :  14151.861345817599 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.827991353896323  train error :  13152.739770051729  validation error :  14150.41100480587 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.5524180791724337  train error :  13152.741029760724  validation error :  14150.382348720848 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.692926262811713  train error :  13152.75050282092  validation error :  14150.442245831284 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.3459094739151233  train error :  13152.857070405686  validation error :  14150.537132181547 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.0027416359532291823  train error :  12595.15258636861  validation error :  13573.162158126368 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.5444785336830842  train error :  13152.947753283053  validation error :  14150.657205476125 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6205706308351374  train error :  13152.372206974098  validation error :  14149.990034311788 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6528525392702023  train error :  13152.79012440967  validation error :  14150.410062368992 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.11868330039432018  train error :  13166.201339252953  validation error :  14170.708426643883 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.0027416359532291823  Best train error :  12595.15258636861  Best validation error :  13573.162158126368  Best testing error :  13149.893170498919 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  2 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.791582101392465  train error :  13151.25303474986  validation error :  14148.69736255332 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.3897327472458496  train error :  13152.562091280008  validation error :  14150.195387113432 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.4056946350785502  train error :  13152.612669969722  validation error :  14150.23137065568 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.15031848402827985  train error :  13153.586302837015  validation error :  14152.206868117135 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.27952233252693226  train error :  13151.920606744872  validation error :  14149.486509796247 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.17208353362940254  train error :  13151.970669387088  validation error :  14149.714321292015 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7798434281391907  train error :  13151.764524183107  validation error :  14149.295330770694 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9581134452401356  train error :  13151.54846328163  validation error :  14148.929150101596 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.1896299310662264  train error :  13151.785000997628  validation error :  14149.377382198772 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8161851563987962  train error :  13152.83464903045  validation error :  14150.604575030966 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.791582101392465  Best train error :  13151.25303474986  Best validation error :  14148.69736255332  Best testing error :  13796.024920018464 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  3 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.7690546252472485  train error :  13151.536098172786  validation error :  14149.171676598662 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9470604197856971  train error :  13152.312447807375  validation error :  14150.058516074516 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6237097107692844  train error :  13151.285803816469  validation error :  14148.82428164617 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.0952306477049073  train error :  13166.705056483328  validation error :  14186.966944611575 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.022481754008752408  train error :  12444.686219870684  validation error :  13496.247154289207 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7542388720096447  train error :  13150.699086916116  validation error :  14148.052643214722 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.35290385832204607  train error :  13150.937455104735  validation error :  14148.379335391583 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.13580856288098286  train error :  13156.301441707314  validation error :  14156.648383906246 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8711099291740666  train error :  13150.549850826981  validation error :  14148.069311511885 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6619151024193943  train error :  13151.64928616544  validation error :  14149.12934236232 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.022481754008752408  Best train error :  12444.686219870684  Best validation error :  13496.247154289207  Best testing error :  13092.308119590063 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  4 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.2446688951131336  train error :  13150.435724725818  validation error :  14147.882694848513 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9904692212582373  train error :  13151.775356770244  validation error :  14149.430256304293 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.741946466197974  train error :  13149.593528970672  validation error :  14147.06727662106 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.2620694343419162  train error :  13150.43689555862  validation error :  14147.918824936412 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6818797371767258  train error :  13151.42232343534  validation error :  14148.908099777134 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.09839666688995452  train error :  13180.126870409264  validation error :  14199.109417931433 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.350978151105799  train error :  13150.731228088722  validation error :  14148.171901834852 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7578899428152844  train error :  13151.045699121496  validation error :  14148.656140736606 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.005268103546186675  train error :  12316.139851333703  validation error :  13400.296599522511 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.10871787450340131  train error :  13178.487884196238  validation error :  14189.70957688056 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.005268103546186675  Best train error :  12316.139851333703  Best validation error :  13400.296599522511  Best testing error :  12840.61636511133 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  5 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.517857624379234  train error :  13150.176569903308  validation error :  14147.638143565318 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.13237475767062679  train error :  13156.302512269733  validation error :  14157.367521016755 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.08510708920697219  train error :  13133.532216062033  validation error :  14160.659935553844 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9030226404724753  train error :  13148.010094742678  validation error :  14145.208557302421 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6358398871249119  train error :  13151.767626712952  validation error :  14149.419800375554 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.20279077670973278  train error :  13150.362228527918  validation error :  14148.006831599105 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.5689936760933914  train error :  13151.744288617923  validation error :  14149.3759784512 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.39180665254643066  train error :  13149.936200864035  validation error :  14147.376564879489 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.2524856625763149  train error :  13150.295291168382  validation error :  14147.738496216609 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.3545492596544223  train error :  13149.561208985926  validation error :  14146.921703459688 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.9030226404724753  Best train error :  13148.010094742678  Best validation error :  14145.208557302421  Best testing error :  13791.535738402617 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  6 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.43680299838796643  train error :  13149.712839842732  validation error :  14147.24331265776 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8676412047411174  train error :  13148.738556682521  validation error :  14146.03819019708 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.33480624821661464  train error :  13149.91351340637  validation error :  14147.44864719019 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7573884305419278  train error :  13147.735878006353  validation error :  14145.096278599009 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9094430506488904  train error :  13152.463454716932  validation error :  14149.86240376378 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.05216712137353685  train error :  12833.64607055728  validation error :  13883.56743813412 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.06008691802661137  train error :  12935.896673147496  validation error :  13981.324235841574 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8952656254755047  train error :  13148.918957544121  validation error :  14145.966102987308 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.24105624044007923  train error :  13150.044686658151  validation error :  14147.650022706246 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.45549545873266195  train error :  13150.584358484384  validation error :  14148.32024305523 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.05216712137353685  Best train error :  12833.64607055728  Best validation error :  13883.56743813412  Best testing error :  13584.300008697439 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  7 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.023318054098146135  train error :  12468.862489529207  validation error :  13554.32561404493 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8041103416622022  train error :  13151.076461730341  validation error :  14148.646173919018 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.04769884959797033  train error :  12784.51720642506  validation error :  13838.396908918687 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.46678075419232745  train error :  13151.182211891432  validation error :  14148.775119644095 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7448185760662797  train error :  13150.080086764048  validation error :  14147.686463021462 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.29419521586084385  train error :  13149.871160313838  validation error :  14147.346559331138 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.12905559915282527  train error :  13157.685339072534  validation error :  14159.597211368486 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.338702067896964  train error :  13150.060581719199  validation error :  14147.637619797906 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.19384105412732167  train error :  13149.705105918632  validation error :  14147.208549873103 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.2098265760435306  train error :  13149.336657117929  validation error :  14146.957193783774 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.023318054098146135  Best train error :  12468.862489529207  Best validation error :  13554.32561404493  Best testing error :  13168.432596145849 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  8 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.3400170364364057  train error :  13149.273629119005  validation error :  14146.811831213665 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.01032594792649022  train error :  12350.702114187761  validation error :  13473.41629763026 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.22888906234298068  train error :  13150.435738153552  validation error :  14148.074276079566 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.34005827986186266  train error :  13150.155809221616  validation error :  14147.79728674306 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.3833061561739005  train error :  13148.042691184053  validation error :  14145.413096158649 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.0655281178607926  train error :  12996.036673161954  validation error :  14038.346156928654 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.3283377630557628  train error :  13148.991992279422  validation error :  14146.501117477495 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.790698179666537  train error :  13150.146553428498  validation error :  14147.350962330169 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.030932272198479938  train error :  12560.83363214736  validation error :  13632.420498436355 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6288373515518807  train error :  13149.79268619978  validation error :  14147.29809688573 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.01032594792649022  Best train error :  12350.702114187761  Best validation error :  13473.41629763026  Best testing error :  12973.604962760075 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  9 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.9226138915798124  train error :  13150.11137014684  validation error :  14147.685576583453 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.9205662743447337  train error :  13149.879314546613  validation error :  14147.606031888194 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.5747271434098854  train error :  13149.390602090702  validation error :  14146.754003085436 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.05580204982355719  train error :  12877.096815718536  validation error :  13924.913464746878 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.019185463106915934  train error :  12424.784831740863  validation error :  13517.713205380946 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.45077081075422554  train error :  13151.369061122805  validation error :  14149.036484157645 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8651329327415918  train error :  13147.056376251781  validation error :  14144.48691466956 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.0831370842309117  train error :  13129.410543329685  validation error :  14158.74857423182 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.6460938272885631  train error :  13151.46498047336  validation error :  14149.085401603317 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.3664757522350306  train error :  13150.252826706543  validation error :  14147.71013293066 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.019185463106915934  Best train error :  12424.784831740863  Best validation error :  13517.713205380946  Best testing error :  13104.524573711855 \u001b[0m\n",
            "\u001b[36m\n",
            " \n",
            "Polynomial degree :  10 \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[91mPenalty :  0.007116444193793203  train error :  12336.473091855096  validation error :  13470.611181954042 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.4164524316750471  train error :  13150.221611841525  validation error :  14147.751466116131 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.14181703101417276  train error :  13153.198589189014  validation error :  14152.780239033827 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.47994877599519203  train error :  13150.796981410784  validation error :  14148.322489970435 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.7419052009215994  train error :  13150.662621657115  validation error :  14147.994235692804 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.393212828169039  train error :  13148.423749754245  validation error :  14146.266700635962 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.49115452358532374  train error :  13149.095992268856  validation error :  14146.82307075992 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.16381353814618604  train error :  13150.457686759642  validation error :  14148.428696323042 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.3833758225907933  train error :  13150.632235699608  validation error :  14148.117798370145 \u001b[0m\n",
            "\u001b[1m\u001b[91mPenalty :  0.8079071691712167  train error :  13149.400118697757  validation error :  14146.887045274927 \u001b[0m\n",
            "\u001b[1m\u001b[91m\u001b[4mBest Penalty :  0.007116444193793203  Best train error :  12336.473091855096  Best validation error :  13470.611181954042  Best testing error :  12932.114787255416 \u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GSzTPm-7tKp"
      },
      "source": [
        "**3D Plot for Gradient Descent**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m1ugE4C7z-W"
      },
      "source": [
        "# qt5 package required to run this cell\n",
        "for i in range(10):                                      #apply polynomial regression for polynomials of degrees from 1 to 10\n",
        "  Xi = poly_features(X, i+1)\n",
        "  X_train, X_test, Y_train, Y_test = splitData(Xi, Y)       #split data into train and test sets           \n",
        "  X_train, Y_train, Y_train_max, Y_train_min = standardize(X_train, Y_train) #standardize train set\n",
        "  X_test, Y_test, Y_test_max, Y_test_min = standardize(X_test, Y_test) #stanardize test set\n",
        "  theta = np.zeros(X_train.shape[1])\n",
        "  theta = np.transpose(theta)\n",
        "  theta = gradient_descent(X_train, Y_train, theta, 0.01, 1000, Y_train_max, Y_train_min)  # calculate weights using gradient descent\n",
        "\n",
        "  Y_pred_train = X_train.dot(theta)\n",
        "  Y_pred_test = X_test.dot(theta)\n",
        "\n",
        "  degreeStr = 'Degree' + str(i)\n",
        "\n",
        "  ax = plt.figure(i).gca(projection=\"3d\")\n",
        "\n",
        "\n",
        "  ax.scatter(X_train[:,1], X_train[:,2], Y_train.flatten(), color='red', marker='+') #ploting points\n",
        "  ax.plot_trisurf(X_train[:,1], X_train[:,2], Y_pred_train.flatten(), cmap=\"viridis\", antialiased=False) #ploting the surface\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jxb4bOTjUpfy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}